{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c853e9d1",
   "metadata": {},
   "source": [
    "# Classification in AOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "957fdde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from gensim.models import word2vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import itertools\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from collections import defaultdict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b85a81cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/diptamath/covid_fake_news/main/data/Constraint_Train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd5b52d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Constraint_Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf9a7353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The CDC currently reports 99031 deaths. In gen...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>States reported 1121 deaths a small rise from ...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Politically Correct Woman (Almost) Uses Pandem...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>#IndiaFightsCorona: We have 1524 #COVID testin...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Populous states can generate large case counts...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              tweet label\n",
       "0   1  The CDC currently reports 99031 deaths. In gen...  real\n",
       "1   2  States reported 1121 deaths a small rise from ...  real\n",
       "2   3  Politically Correct Woman (Almost) Uses Pandem...  fake\n",
       "3   4  #IndiaFightsCorona: We have 1524 #COVID testin...  real\n",
       "4   5  Populous states can generate large case counts...  real"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3df8c87",
   "metadata": {},
   "source": [
    "## Наивные методы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bcf6d3",
   "metadata": {},
   "source": [
    "### OneHotEncoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a3d1f5",
   "metadata": {},
   "source": [
    "Убираем ошибку, которая может возникнуть при работе с pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b70434a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pymorphy2_311_hotfix():\n",
    "    from inspect import getfullargspec\n",
    "    from pymorphy2.units.base import BaseAnalyzerUnit\n",
    "\n",
    "    def _get_param_names_311(klass):\n",
    "        if klass.__init__ is object.__init__:\n",
    "            return []\n",
    "        args = getfullargspec(klass.__init__).args\n",
    "        return sorted(args[1:])\n",
    "\n",
    "    setattr(BaseAnalyzerUnit, '_get_param_names', _get_param_names_311)\n",
    "\n",
    "pymorphy2_311_hotfix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7f8456",
   "metadata": {},
   "source": [
    "Проводим разбиение на токены, леммы и one hot кодирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e394438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot(df):\n",
    "    lemms = []\n",
    "    morph = MorphAnalyzer()    \n",
    "    stops = stopwords.words(\"english\")\n",
    "    \n",
    "    for row in df.tweet:\n",
    "        row = re.sub(r\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", \" \", row)\n",
    "        row = re.sub(\"[^a-zA-Z]\",\" \", row)\n",
    "        lemms.append([morph.parse(token)[0].normal_form for token in word_tokenize(row.lower()) if token not in ' )(.,1/\\?#-@:;&^%$_+=' and token not in stops and len(token) > 2])\n",
    "    df['lemms'] = [' '.join(lemm) for lemm in lemms]\n",
    "    \n",
    "    unique_words = set()\n",
    "    for sentence in lemms:\n",
    "        for word in sentence:\n",
    "            unique_words.add(word)\n",
    "\n",
    "    word_to_index = {}\n",
    "    for i, word in enumerate(unique_words):\n",
    "        word_to_index[word] = i\n",
    "\n",
    "    one_hot_vectors = []\n",
    "    for sentence in lemms:\n",
    "        sentence_vectors = []\n",
    "        for word in sentence:\n",
    "            vector = np.zeros(len(unique_words), dtype='int')\n",
    "            vector[word_to_index[word]] = 1\n",
    "            sentence_vectors.append(vector)\n",
    "        one_hot_vectors.append(sentence_vectors)\n",
    "        \n",
    "    print('ok')\n",
    "    return one_hot_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d1fe4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "one_hot_vectors = get_one_hot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc60afe6",
   "metadata": {},
   "source": [
    "Суммируем векторы слов по текстам для получения векторов текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f9d4db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_one_hot = [sum(sentences) for sentences in one_hot_vectors]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a3f5ad",
   "metadata": {},
   "source": [
    "Приводим метки к числовому типу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e8ba39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>lemms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The CDC currently reports 99031 deaths. In gen...</td>\n",
       "      <td>1</td>\n",
       "      <td>cdc currently reports deaths general discrepan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>States reported 1121 deaths a small rise from ...</td>\n",
       "      <td>1</td>\n",
       "      <td>states reported deaths small rise last tuesday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Politically Correct Woman (Almost) Uses Pandem...</td>\n",
       "      <td>0</td>\n",
       "      <td>politically correct woman almost uses pandemic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>#IndiaFightsCorona: We have 1524 #COVID testin...</td>\n",
       "      <td>1</td>\n",
       "      <td>indiafightscorona covid testing laboratories i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Populous states can generate large case counts...</td>\n",
       "      <td>1</td>\n",
       "      <td>populous states generate large case counts loo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6415</th>\n",
       "      <td>6416</td>\n",
       "      <td>A tiger tested positive for COVID-19 please st...</td>\n",
       "      <td>0</td>\n",
       "      <td>tiger tested positive covid please stay away p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6416</th>\n",
       "      <td>6417</td>\n",
       "      <td>???Autopsies prove that COVID-19 is??� a blood...</td>\n",
       "      <td>0</td>\n",
       "      <td>autopsies prove covid blood clot pneumonia oug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6417</th>\n",
       "      <td>6418</td>\n",
       "      <td>_A post claims a COVID-19 vaccine has already ...</td>\n",
       "      <td>0</td>\n",
       "      <td>post claims covid vaccine already developed ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6418</th>\n",
       "      <td>6419</td>\n",
       "      <td>Aamir Khan Donate 250 Cr. In PM Relief Cares Fund</td>\n",
       "      <td>0</td>\n",
       "      <td>aamir khan donate relief cares fund</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6419</th>\n",
       "      <td>6420</td>\n",
       "      <td>It has been 93 days since the last case of COV...</td>\n",
       "      <td>1</td>\n",
       "      <td>days since last case covid acquired locally un...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6420 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              tweet  label  \\\n",
       "0        1  The CDC currently reports 99031 deaths. In gen...      1   \n",
       "1        2  States reported 1121 deaths a small rise from ...      1   \n",
       "2        3  Politically Correct Woman (Almost) Uses Pandem...      0   \n",
       "3        4  #IndiaFightsCorona: We have 1524 #COVID testin...      1   \n",
       "4        5  Populous states can generate large case counts...      1   \n",
       "...    ...                                                ...    ...   \n",
       "6415  6416  A tiger tested positive for COVID-19 please st...      0   \n",
       "6416  6417  ???Autopsies prove that COVID-19 is??� a blood...      0   \n",
       "6417  6418  _A post claims a COVID-19 vaccine has already ...      0   \n",
       "6418  6419  Aamir Khan Donate 250 Cr. In PM Relief Cares Fund      0   \n",
       "6419  6420  It has been 93 days since the last case of COV...      1   \n",
       "\n",
       "                                                  lemms  \n",
       "0     cdc currently reports deaths general discrepan...  \n",
       "1     states reported deaths small rise last tuesday...  \n",
       "2     politically correct woman almost uses pandemic...  \n",
       "3     indiafightscorona covid testing laboratories i...  \n",
       "4     populous states generate large case counts loo...  \n",
       "...                                                 ...  \n",
       "6415  tiger tested positive covid please stay away p...  \n",
       "6416  autopsies prove covid blood clot pneumonia oug...  \n",
       "6417  post claims covid vaccine already developed ca...  \n",
       "6418                aamir khan donate relief cares fund  \n",
       "6419  days since last case covid acquired locally un...  \n",
       "\n",
       "[6420 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label = pd.get_dummies(df.label, drop_first=True, dtype=int)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1205de53",
   "metadata": {},
   "source": [
    "Обучим модель линейной регрессии на основе нашего one hot кодирования. Вероятность ~91%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64682e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9166666666666666"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_one_hot[:6000], df.label[:6000])\n",
    "model.score(text_one_hot[6000:], df.label[6000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "445ac617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.92       202\n",
      "           1       0.95      0.89      0.92       218\n",
      "\n",
      "    accuracy                           0.92       420\n",
      "   macro avg       0.92      0.92      0.92       420\n",
      "weighted avg       0.92      0.92      0.92       420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df.label[6000:], model.predict(text_one_hot[6000:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78667c6b",
   "metadata": {},
   "source": [
    "Обучим RandomForestClassifier, получим вероятность ~86%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a64ceda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=200, random_state=42, max_depth=20)\n",
    "forest.fit(text_one_hot[:6000], df.label[:6000])\n",
    "forest.score(text_one_hot[6000:], df.label[6000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d218318c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.93      0.86       202\n",
      "           1       0.92      0.78      0.84       218\n",
      "\n",
      "    accuracy                           0.85       420\n",
      "   macro avg       0.86      0.85      0.85       420\n",
      "weighted avg       0.86      0.85      0.85       420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df.label[6000:], forest.predict(text_one_hot[6000:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0948e465",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d5881a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df.lemms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf173ea",
   "metadata": {},
   "source": [
    "Обучим модель линейной регрессии на основе CountVectorizer. Вероятность ~91%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccc2c919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9166666666666666"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect_model = LogisticRegression(random_state=42)\n",
    "count_vect_model.fit(X[:6000], df.label[:6000])\n",
    "count_vect_model.score(X[6000:], df.label[6000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1f167b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.92       202\n",
      "           1       0.95      0.89      0.92       218\n",
      "\n",
      "    accuracy                           0.92       420\n",
      "   macro avg       0.92      0.92      0.92       420\n",
      "weighted avg       0.92      0.92      0.92       420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df.label[6000:], count_vect_model.predict(X[6000:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b26b966",
   "metadata": {},
   "source": [
    "Обучим RandomForestClassifier, получим вероятность ~87%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76f5693a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8595238095238096"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect_forest = RandomForestClassifier(n_estimators=200, random_state=42, max_depth=20)\n",
    "count_vect_forest.fit(X[:6000], df.label[:6000])\n",
    "count_vect_forest.score(X[6000:], df.label[6000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbfe0827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.87       202\n",
      "           1       0.93      0.78      0.85       218\n",
      "\n",
      "    accuracy                           0.86       420\n",
      "   macro avg       0.87      0.86      0.86       420\n",
      "weighted avg       0.87      0.86      0.86       420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df.label[6000:], count_vect_forest.predict(X[6000:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3485f8bf",
   "metadata": {},
   "source": [
    "### Word2Vec + TfIdf weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e30705c",
   "metadata": {},
   "source": [
    "Делаем векторизацию с помощью word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b58df47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.33 s\n",
      "Wall time: 1.29 s\n"
     ]
    }
   ],
   "source": [
    "texts = [[token for token in row.split()] for row in df.lemms]\n",
    "\n",
    "%time model_en = word2vec.Word2Vec(texts, workers=1, vector_size=300, min_count=10, window=5, sample=1e-3, alpha=0.07, min_alpha=0.001, sg=1, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3366317",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_en.init_sims()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f21c872",
   "metadata": {},
   "source": [
    "Считаем TfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab8ba44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(df.lemms) \n",
    "word_idf_weight = defaultdict(lambda: max(tfidf.idf_), [(word, tfidf.idf_[i]) for word, i in tfidf.vocabulary_.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaa76fb",
   "metadata": {},
   "source": [
    "Получаем взвешенный эмбендинг за счет весов TfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d141ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text):\n",
    "    result = []\n",
    "    \n",
    "    for word in text:\n",
    "        if word in model_en.wv:\n",
    "            result.append(model_en.wv[word] * word_idf_weight[word])\n",
    "    \n",
    "    if len(result):\n",
    "        result = np.sum(result, axis=0)\n",
    "    else:\n",
    "        result = np.zeros(300)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79b70bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [get_embedding(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59d4ac8",
   "metadata": {},
   "source": [
    "Обучим модель LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72e6750d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = LogisticRegression(random_state=42)\n",
    "model2.fit(features[:6000], df.label[:6000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81004739",
   "metadata": {},
   "source": [
    "Получили результат хуже чем при OneHot энкодинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48f32f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9023809523809524"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.score(features[6000:], df.label[6000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4f42997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90       202\n",
      "           1       0.92      0.89      0.90       218\n",
      "\n",
      "    accuracy                           0.90       420\n",
      "   macro avg       0.90      0.90      0.90       420\n",
      "weighted avg       0.90      0.90      0.90       420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df.label[6000:], model2.predict(features[6000:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1897edf5",
   "metadata": {},
   "source": [
    "Обучим модель RandomForestClassifier. Вероятность ~91%. Но немного хуже чем у OneHot энкодинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5e68d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9119047619047619"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest2 = RandomForestClassifier(n_estimators=200, random_state=42, max_depth=20)\n",
    "forest2.fit(features[:6000], df.label[:6000])\n",
    "forest2.score(features[6000:], df.label[6000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6285606d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91       202\n",
      "           1       0.93      0.89      0.91       218\n",
      "\n",
      "    accuracy                           0.91       420\n",
      "   macro avg       0.91      0.91      0.91       420\n",
      "weighted avg       0.91      0.91      0.91       420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df.label[6000:], forest2.predict(features[6000:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e405742f",
   "metadata": {},
   "source": [
    "Обучим модель KNeighborsClassifier. Вероятность ~90%. Хуже чем у OneHot энкодинг и RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55ad7fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(features[:6000], df.label[:6000])\n",
    "knn.score(features[6000:], df.label[6000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3dc1237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90       202\n",
      "           1       0.92      0.88      0.90       218\n",
      "\n",
      "    accuracy                           0.90       420\n",
      "   macro avg       0.90      0.90      0.90       420\n",
      "weighted avg       0.90      0.90      0.90       420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df.label[6000:], knn.predict(features[6000:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd4fa83",
   "metadata": {},
   "source": [
    "**Почему модель LogisticRegression показала значения хуже чем при OneHotEncoding ведь обработка в этот раз лучше?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5b1482",
   "metadata": {},
   "source": [
    "### Thematic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4087b505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "from gensim.models import ldamodel\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c3f84c",
   "metadata": {},
   "source": [
    "Сделаем корпус для обучения модели LdaModel и обучим ее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6380c077",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16ce8c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = ldamodel.LdaModel(corpus=corpus,\n",
    "                        id2word=dictionary,\n",
    "                        num_topics=25,\n",
    "                        alpha='auto',\n",
    "                        eta='auto',\n",
    "                        iterations = 20,\n",
    "                        passes = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da06c193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(11,\n",
       "  '0.027*\"coronavirus\" + 0.024*\"covid\" + 0.019*\"took\" + 0.019*\"cures\" + 0.016*\"one\" + 0.015*\"canada\" + 0.014*\"tips\" + 0.014*\"tweet\" + 0.013*\"safety\" + 0.013*\"nashville\"'),\n",
       " (17,\n",
       "  '0.041*\"covid\" + 0.032*\"coronavirus\" + 0.027*\"children\" + 0.024*\"people\" + 0.022*\"old\" + 0.017*\"staff\" + 0.017*\"early\" + 0.015*\"get\" + 0.014*\"could\" + 0.013*\"place\"'),\n",
       " (6,\n",
       "  '0.135*\"cases\" + 0.063*\"covid\" + 0.051*\"total\" + 0.049*\"new\" + 0.046*\"number\" + 0.044*\"confirmed\" + 0.032*\"case\" + 0.027*\"active\" + 0.026*\"report\" + 0.019*\"today\"'),\n",
       " (2,\n",
       "  '0.060*\"covid\" + 0.029*\"people\" + 0.025*\"spread\" + 0.022*\"amp\" + 0.016*\"health\" + 0.014*\"help\" + 0.013*\"learn\" + 0.013*\"facility\" + 0.013*\"others\" + 0.012*\"face\"'),\n",
       " (4,\n",
       "  '0.065*\"covid\" + 0.029*\"amp\" + 0.016*\"health\" + 0.010*\"child\" + 0.009*\"continue\" + 0.009*\"available\" + 0.009*\"use\" + 0.009*\"work\" + 0.009*\"working\" + 0.009*\"cdc\"')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.show_topics(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f7f36f",
   "metadata": {},
   "source": [
    "К каким топикам и с какой вероятностью относится первый текст в датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a26c9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.12732011),\n",
       " (5, 0.23361748),\n",
       " (12, 0.15188138),\n",
       " (15, 0.086752415),\n",
       " (16, 0.3440987)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.get_document_topics(corpus)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e8f9fd",
   "metadata": {},
   "source": [
    "Сделаем эмбендинг на основе тематического моделирования. Так как lda.get_document_topics предоставляет не 25 топиков с вероятностями, а зачастую меньше, то сначала создадим список с 25 нулевыми значениями, а потом будет заполнять значения в порядке выданных тем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "169f2a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_lda(text):\n",
    "    result = []\n",
    "    \n",
    "    for bow_text in lda.get_document_topics(corpus):\n",
    "        vector = [0.0]*25\n",
    "        for i, elem in bow_text:\n",
    "            vector[i] = elem \n",
    "        result.append(vector)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6a3b9e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_features = get_embedding_lda(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be33311f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7880952380952381"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = LogisticRegression(random_state=42)\n",
    "model3.fit(bow_features[:6000], df.label[:6000])\n",
    "model3.score(bow_features[6000:], df.label[6000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7c2389c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.75      0.77       202\n",
      "           1       0.78      0.82      0.80       218\n",
      "\n",
      "    accuracy                           0.79       420\n",
      "   macro avg       0.79      0.79      0.79       420\n",
      "weighted avg       0.79      0.79      0.79       420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df.label[6000:], model3.predict(bow_features[6000:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "85b98434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.830952380952381"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_forest = RandomForestClassifier(n_estimators=200, random_state=42, max_depth=20)\n",
    "bow_forest.fit(bow_features[:6000], df.label[:6000])\n",
    "bow_forest.score(bow_features[6000:], df.label[6000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "81108b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83       202\n",
      "           1       0.84      0.83      0.84       218\n",
      "\n",
      "    accuracy                           0.83       420\n",
      "   macro avg       0.83      0.83      0.83       420\n",
      "weighted avg       0.83      0.83      0.83       420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df.label[6000:], bow_forest.predict(bow_features[6000:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d07f77d",
   "metadata": {},
   "source": [
    "Достаточно неплохие показатели. ~81%\n",
    "\n",
    "**Есть какие-то советы/возможности для улучшения показателей тематического моделирования?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f694ae90",
   "metadata": {},
   "source": [
    "## CNN и RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ee0776",
   "metadata": {},
   "source": [
    "### PyTorch Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b2369847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (input_layer): Linear(in_features=300, out_features=150, bias=True)\n",
      "  (out): Linear(in_features=150, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.input_layer = nn.Linear(300, 150)\n",
    "        self.out = nn.Linear(150, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.input_layer(x))\n",
    "        return torch.sigmoid(self.out(x))\n",
    "    \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "34e880e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1d4f8518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_torch_embedding(text):\n",
    "    result = []\n",
    "    \n",
    "    for word in text.split():\n",
    "        if word in model_en.wv:\n",
    "            result.append(model_en.wv[word])\n",
    "    \n",
    "    if len(result):\n",
    "        result = np.average(result, axis=0)\n",
    "    else:\n",
    "        result = np.zeros(300)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6c71224e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6420/6420 [00:00<00:00, 26593.29it/s]\n"
     ]
    }
   ],
   "source": [
    "features = [get_torch_embedding(text) for text in tqdm(df.lemms)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7af54a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, df.label.to_list(), test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "135d6494",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data = torch.tensor(X_train).float()\n",
    "targets = torch.tensor(y_train).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8d3f826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(in_data, targets, batch_size=16):\n",
    "    for i in tqdm(range(0, in_data.shape[0], batch_size)):\n",
    "        batch_x = in_data[i:i + batch_size]\n",
    "        batch_y = targets[i:i + batch_size]\n",
    "        optimizer.zero_grad()\n",
    "        output = net(batch_x)\n",
    "        loss = criterion(output.squeeze(), batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "208684ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 1725.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5519, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 1797.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5518, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 1800.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5518, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 1822.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5518, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 1837.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5517, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 1780.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5517, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 1768.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5517, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 1785.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5517, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 1799.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5517, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 1836.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5516, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    train_one_epoch(in_data, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4163553f",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data_test = torch.tensor(X_test).float()\n",
    "targets_test = torch.tensor(y_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "71c0cafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = net(in_data_test).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ce0e8d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = (output.cpu() > 0.5) == targets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1058e688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8722741433021807"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.sum().item() / len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b512d34",
   "metadata": {},
   "source": [
    "### PyTorch + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "438b2cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetLSTM(\n",
      "  (lstm): LSTM(300, 150)\n",
      "  (out): Linear(in_features=150, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NetLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(NetLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(300, 150)\n",
    "        self.out = nn.Linear(150, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeddings, (shortterm, longterm) = self.lstm(x.transpose(0, 1))\n",
    "        prediction = torch.sigmoid(self.out(longterm))\n",
    "        return prediction\n",
    "\n",
    "\n",
    "Net_LSTM = NetLSTM()\n",
    "print(Net_LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4c8932",
   "metadata": {},
   "source": [
    "Возьмем взвешенный эмбединг на основе Word2Vec с TfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a8cbb5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_LSTM = [get_embedding(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d1167b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features_LSTM, df.label.to_list(), test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1c725069",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data = torch.tensor(X_train).float()\n",
    "targets = torch.tensor(y_train).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "248df9f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4815, 300])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5fb9b1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(Net_LSTM.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "be4d652d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(in_data, targets, batch_size=16):\n",
    "    for i in tqdm(range(0, in_data.shape[0], batch_size)):\n",
    "        batch_x = in_data[i:i + batch_size]\n",
    "        batch_y = targets[i:i + batch_size]\n",
    "        optimizer.zero_grad()\n",
    "        output = Net_LSTM(batch_x)\n",
    "        loss = criterion(output.reshape(-1), batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a5e5ca59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:03<00:00, 84.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2507, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:03<00:00, 84.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2509, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:03<00:00, 83.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2509, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:03<00:00, 83.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2510, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:03<00:00, 82.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2509, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Net_LSTM.train()\n",
    "for i in range(5):\n",
    "    train_one_epoch(in_data, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e299bb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5383177570093458"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_data_test = torch.tensor(X_test).float()\n",
    "targets_test = torch.tensor(y_test).float()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = Net_LSTM(in_data_test).reshape(-1)\n",
    "    \n",
    "result = (output.cpu() > 0.5) == targets_test\n",
    "result.sum().item() / len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13873f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b281d03f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601d951e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba3766b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b573924",
   "metadata": {},
   "source": [
    "**Ниже попробовал использовать выходной слой LSTM, тут вроде более менее результат. Правда нужно его еше улучшить немного чтобы был больше 0.91%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e6ca69d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NewNetLSTM(\n",
      "  (lstm): LSTM(300, 128, batch_first=True)\n",
      "  (lin): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (out): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NewNetLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=300, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        self.lin = nn.Linear(128, 64)\n",
    "        self.out = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = F.relu(self.lin(x))\n",
    "        prediction = torch.sigmoid(self.out(x))\n",
    "        return prediction\n",
    "    \n",
    "\n",
    "New_Net_LSTM = NewNetLSTM()\n",
    "print(New_Net_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7630c1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_train_one_epoch(in_data, targets, batch_size=16):\n",
    "    for i in tqdm(range(0, in_data.shape[0], batch_size)):\n",
    "        batch_x = in_data[i:i + batch_size]\n",
    "        batch_y = targets[i:i + batch_size]\n",
    "        optimizer.zero_grad()\n",
    "        output = New_Net_LSTM(batch_x)\n",
    "        loss = criterion(output.reshape(-1), batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)\n",
    "\n",
    "optimizer = optim.SGD(New_Net_LSTM.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8ee0d37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 594.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1630, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 677.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0926, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 666.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0757, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 661.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0744, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 699.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0739, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 711.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0727, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 721.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0719, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 679.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0722, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 723.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0718, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 691.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0717, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "New_Net_LSTM.train()\n",
    "for i in range(10):\n",
    "    new_train_one_epoch(in_data, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ce9595a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.897196261682243"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_data_test = torch.tensor(X_test).float()\n",
    "targets_test = torch.tensor(y_test).float()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = New_Net_LSTM(in_data_test).reshape(-1)\n",
    "    \n",
    "result = (output.cpu() > 0.5) == targets_test\n",
    "result.sum().item() / len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4ab423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0673cf4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a960afaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b42541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb387183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3328c561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9bf741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ec3a79d",
   "metadata": {},
   "source": [
    "**Решил поэксперементировать LSTM в связке с Conv слоями, но как-то не оч. По функции потерь видно что модель не обучается особо.**\n",
    "\n",
    "**+ проблема с batch_size. Для Conv1d первый параметр равен batch_size и если при тренировке мы его можем задать равным batch_size, то при оценке на тестовых данных мы туда закидываем сразу все данные (1000+) и модель ломается (ошибка есть ниже)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9641a70f",
   "metadata": {},
   "source": [
    "**Как в реальных задачах решается проблема с первым параметром для Conv1d? Или обучают и тестируют батчами одного и того же размера? (В этой работе в первый трогаю torch, но в Keras таких проблем не встречал)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac9e4db",
   "metadata": {},
   "source": [
    "**Куда копать? Или Conv слои с LSTM лучше не использовать и пробовать что-то другое?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3bbca9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NewNetLSTM(\n",
      "  (lstm): LSTM(300, 128, batch_first=True)\n",
      "  (conv1): Conv1d(1, 128, kernel_size=(3,), stride=(1,))\n",
      "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (flattened_tensor): Flatten(start_dim=1, end_dim=-1)\n",
      "  (lin): Linear(in_features=504, out_features=32, bias=True)\n",
      "  (out): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NewNetLSTM(nn.Module):\n",
    "    def __init__(self, batch_size=1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=300, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        self.conv1 = nn.Conv1d(batch_size, 128, kernel_size=3)\n",
    "        self.pool = nn.MaxPool1d(2, 2)\n",
    "        self.flattened_tensor = nn.Flatten()\n",
    "        self.lin = nn.Linear(504, 32)\n",
    "        self.out = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 16)\n",
    "        x = self.flattened_tensor(x)\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "        x = F.relu(self.lin(x))\n",
    "        prediction = torch.sigmoid(self.out(x))\n",
    "        return prediction\n",
    "    \n",
    "\n",
    "New_Net_LSTM = NewNetLSTM()\n",
    "print(New_Net_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a35fc938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_train_one_epoch(in_data, targets, batch_size=16):\n",
    "    global New_Net_LSTM\n",
    "    New_Net_LSTM = NewNetLSTM(batch_size)\n",
    "    \n",
    "    for i in tqdm(range(0, in_data.shape[0], batch_size)):\n",
    "        batch_x = in_data[i:i + batch_size]\n",
    "        batch_y = targets[i:i + batch_size]\n",
    "        if len(batch_x) != batch_size:\n",
    "            continue\n",
    "        optimizer.zero_grad()\n",
    "        output = New_Net_LSTM(batch_x)\n",
    "        loss = criterion(output.reshape(-1), batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)\n",
    "\n",
    "optimizer = optim.SGD(New_Net_LSTM.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4207d30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7ea25c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 517.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2481, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 507.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2557, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 512.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2620, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 514.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2477, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 515.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2534, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 523.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2523, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 515.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2505, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 509.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2574, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 517.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2557, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 531.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2570, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "New_Net_LSTM.train()\n",
    "for i in range(10):\n",
    "    new_train_one_epoch(in_data, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "378b67a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [128, 16, 3], expected input[1, 1605, 128] to have 16 channels, but got 1605 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m targets_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y_test)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 5\u001b[0m     output \u001b[38;5;241m=\u001b[39m New_Net_LSTM(in_data_test)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      7\u001b[0m result \u001b[38;5;241m=\u001b[39m (output\u001b[38;5;241m.\u001b[39mcpu() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m) \u001b[38;5;241m==\u001b[39m targets_test\n\u001b[0;32m      8\u001b[0m result\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(result)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[69], line 13\u001b[0m, in \u001b[0;36mNewNetLSTM.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     12\u001b[0m     x, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(x)\n\u001b[1;32m---> 13\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x))\n\u001b[0;32m     14\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(x)\n\u001b[0;32m     15\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m16\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:310\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:306\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    304\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    305\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    307\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [128, 16, 3], expected input[1, 1605, 128] to have 16 channels, but got 1605 channels instead"
     ]
    }
   ],
   "source": [
    "in_data_test = torch.tensor(X_test).float()\n",
    "targets_test = torch.tensor(y_test).float()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = New_Net_LSTM(in_data_test).reshape(-1)\n",
    "    \n",
    "result = (output.cpu() > 0.5) == targets_test\n",
    "result.sum().item() / len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4dd6e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282b7c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef991b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
