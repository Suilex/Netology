{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUIwTg1X2jRm"
      },
      "source": [
        "### Thematic modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lU_fMqg92r3F"
      },
      "source": [
        "#### Data processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCWkIfCGvJHS"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "import bz2\n",
        "import regex\n",
        "from tqdm import tqdm\n",
        "from scipy import sparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wzfzhSewB--",
        "outputId": "40dc170c-f3f3-48c7-9031-e9a04d0f557e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "%pylab inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azzpDvSUwCBc",
        "outputId": "6b05e82c-1b06-48e5-a36a-99bbd50f7756"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "201030it [00:45, 4422.65it/s]\n"
          ]
        }
      ],
      "source": [
        "responses = []\n",
        "with bz2.BZ2File('banki_responses (1).json.bz2', 'r') as thefile:\n",
        "    for row in tqdm(thefile):\n",
        "        resp = json.loads(row)\n",
        "        if not resp['rating_not_checked'] and (len(resp['text'].split()) > 0):\n",
        "            responses.append(resp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKhST8E_wFOe",
        "outputId": "b8ec0b7b-77a9-4b38-ea95-0ac07a23481c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'city': 'г. Саратов',\n",
              " 'rating_not_checked': False,\n",
              " 'title': 'Карта ко вкладу',\n",
              " 'num_comments': 0,\n",
              " 'bank_license': 'лицензия № 880',\n",
              " 'author': 'ronnichka',\n",
              " 'bank_name': 'Югра',\n",
              " 'datetime': '2015-06-03 20:56:57',\n",
              " 'text': 'Здравствуйте! Хотела написать, что мне месяц не выдают карту ко вкладу, ссылаясь на \"нам же их из Самары везут\" (на секундочку 5 часов езды от нашего города). Но! Прочитала, что людям 3,5 месяцев не выдают карту, и поняла, что у меня все хорошо, пока что. И подарок мне дали, и кулер в отделении есть. Так что я, конечно, готова ждать. Правда хотелось бы не очень долго.',\n",
              " 'rating_grade': 3}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "responses[99]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTWhCHIT2zAm"
      },
      "source": [
        "#### Text analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMCZdaxj3hbu"
      },
      "source": [
        "***1. Посчитайте количество отзывов в разных городах и на разные банки***\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpZD465Z3G3-",
        "outputId": "a8e3e60d-64f8-45ef-b57c-83bc00bf3649"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "153499"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(responses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2HXjUDq94CV"
      },
      "source": [
        "Кол-во отзывов по разным банкам и городам лежат в переменных banks и cities соответсвенно"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CyacOVd3oIN",
        "outputId": "51528433-4f3a-4b59-825b-e6c5dd18eafd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Кол-во банков: 670\n",
            "Кол-во городов: 5236\n"
          ]
        }
      ],
      "source": [
        "banks = dict()\n",
        "cities = dict()\n",
        "\n",
        "for resp in responses:\n",
        "  key_bank = resp.get(\"bank_name\").lower()\n",
        "  key_city = resp.get(\"city\").lower() if resp.get(\"city\") is not None else None\n",
        "\n",
        "  if (key_bank in banks):\n",
        "    banks[key_bank] += 1\n",
        "  else:\n",
        "    banks[key_bank] = 1\n",
        "\n",
        "  if (key_city in banks):\n",
        "    cities[key_city] += 1\n",
        "  else:\n",
        "    cities[key_city] = 1\n",
        "\n",
        "\n",
        "print(\"Кол-во банков: {}\".format(len(banks)))\n",
        "print(\"Кол-во городов: {}\".format(len(cities)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Y6X5e3i9x-1"
      },
      "source": [
        "Первые 10 банков по количеству отзывов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHzCbKcl5Vb_",
        "outputId": "c9501e57-e696-4a9f-964c-c318a223e6b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['сбербанк россии', 26327],\n",
              " ['альфа-банк', 10224],\n",
              " ['втб 24', 8185],\n",
              " ['русский стандарт', 7943],\n",
              " ['хоум кредит банк', 7549],\n",
              " ['тинькофф банк', 5387],\n",
              " ['национальный банк «траст»', 4607],\n",
              " ['ренессанс кредит', 3849],\n",
              " ['связной банк', 3775],\n",
              " ['отп банк', 3237]]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sorted([[x, y] for x, y in banks.items()], key=lambda elem: elem[1], reverse=True)[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOzm8iNJ-qcN"
      },
      "source": [
        "***2. Постройте гистограмы длин текстов в символах и в словах***\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "l3xqcnwx3JsF",
        "outputId": "1008f36f-cf88-4a14-9535-ae616155743a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>city</th>\n",
              "      <th>rating_not_checked</th>\n",
              "      <th>title</th>\n",
              "      <th>num_comments</th>\n",
              "      <th>bank_license</th>\n",
              "      <th>author</th>\n",
              "      <th>bank_name</th>\n",
              "      <th>datetime</th>\n",
              "      <th>text</th>\n",
              "      <th>rating_grade</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>г. Москва</td>\n",
              "      <td>False</td>\n",
              "      <td>Жалоба</td>\n",
              "      <td>0</td>\n",
              "      <td>лицензия № 2562</td>\n",
              "      <td>uhnov1</td>\n",
              "      <td>Бинбанк</td>\n",
              "      <td>2015-06-08 12:50:54</td>\n",
              "      <td>Добрый день! Я не являюсь клиентом банка и пор...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>г. Новосибирск</td>\n",
              "      <td>False</td>\n",
              "      <td>Не могу пользоваться услугой Сбербанк он-лайн</td>\n",
              "      <td>0</td>\n",
              "      <td>лицензия № 1481</td>\n",
              "      <td>Foryou</td>\n",
              "      <td>Сбербанк России</td>\n",
              "      <td>2015-06-08 11:09:57</td>\n",
              "      <td>Доброго дня! Являюсь держателем зарплатной кар...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>г. Москва</td>\n",
              "      <td>False</td>\n",
              "      <td>Двойное списание за один товар.</td>\n",
              "      <td>1</td>\n",
              "      <td>лицензия № 2562</td>\n",
              "      <td>Vladimir84</td>\n",
              "      <td>Бинбанк</td>\n",
              "      <td>2015-06-05 20:14:28</td>\n",
              "      <td>Здравствуйте!  Дублирую свое заявление от 03.0...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>г. Ставрополь</td>\n",
              "      <td>False</td>\n",
              "      <td>Меняют проценты комиссии  не предупредив и не ...</td>\n",
              "      <td>2</td>\n",
              "      <td>лицензия № 1481</td>\n",
              "      <td>643609</td>\n",
              "      <td>Сбербанк России</td>\n",
              "      <td>2015-06-05 13:51:01</td>\n",
              "      <td>Добрый день!! Я открыл расчетный счет в СберБа...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>г. Челябинск</td>\n",
              "      <td>False</td>\n",
              "      <td>Верните денежные средства за страховку</td>\n",
              "      <td>1</td>\n",
              "      <td>лицензия № 2766</td>\n",
              "      <td>anfisa-2003</td>\n",
              "      <td>ОТП Банк</td>\n",
              "      <td>2015-06-05 10:58:12</td>\n",
              "      <td>04.03.2015 г. взяла кредит в вашем банке, заяв...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             city  rating_not_checked  \\\n",
              "0       г. Москва               False   \n",
              "1  г. Новосибирск               False   \n",
              "2       г. Москва               False   \n",
              "3   г. Ставрополь               False   \n",
              "4    г. Челябинск               False   \n",
              "\n",
              "                                               title  num_comments  \\\n",
              "0                                             Жалоба             0   \n",
              "1      Не могу пользоваться услугой Сбербанк он-лайн             0   \n",
              "2                    Двойное списание за один товар.             1   \n",
              "3  Меняют проценты комиссии  не предупредив и не ...             2   \n",
              "4             Верните денежные средства за страховку             1   \n",
              "\n",
              "      bank_license       author        bank_name             datetime  \\\n",
              "0  лицензия № 2562       uhnov1          Бинбанк  2015-06-08 12:50:54   \n",
              "1  лицензия № 1481       Foryou  Сбербанк России  2015-06-08 11:09:57   \n",
              "2  лицензия № 2562   Vladimir84          Бинбанк  2015-06-05 20:14:28   \n",
              "3  лицензия № 1481       643609  Сбербанк России  2015-06-05 13:51:01   \n",
              "4  лицензия № 2766  anfisa-2003         ОТП Банк  2015-06-05 10:58:12   \n",
              "\n",
              "                                                text  rating_grade  \n",
              "0  Добрый день! Я не являюсь клиентом банка и пор...           NaN  \n",
              "1  Доброго дня! Являюсь держателем зарплатной кар...           NaN  \n",
              "2  Здравствуйте!  Дублирую свое заявление от 03.0...           NaN  \n",
              "3  Добрый день!! Я открыл расчетный счет в СберБа...           NaN  \n",
              "4  04.03.2015 г. взяла кредит в вашем банке, заяв...           NaN  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame(responses)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWXylQ-HG7K8",
        "outputId": "3bfd9e64-5286-4522-a101-7bc4df614d05"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Suile\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from string import punctuation\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MppYWtzNFeUb"
      },
      "outputs": [],
      "source": [
        "df[\"words_counter\"] = [len([token for token in word_tokenize(text) if token not in punctuation]) for text in df.text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zkJJni8-29c"
      },
      "outputs": [],
      "source": [
        "df[\"symbols_counter\"] = [len(text) for text in df.text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Y7Gh-l9--2_0",
        "outputId": "80ac6648-75dc-42ef-ae1e-cbb4b95975aa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>city</th>\n",
              "      <th>rating_not_checked</th>\n",
              "      <th>title</th>\n",
              "      <th>num_comments</th>\n",
              "      <th>bank_license</th>\n",
              "      <th>author</th>\n",
              "      <th>bank_name</th>\n",
              "      <th>datetime</th>\n",
              "      <th>text</th>\n",
              "      <th>rating_grade</th>\n",
              "      <th>words_counter</th>\n",
              "      <th>symbols_counter</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>г. Москва</td>\n",
              "      <td>False</td>\n",
              "      <td>Жалоба</td>\n",
              "      <td>0</td>\n",
              "      <td>лицензия № 2562</td>\n",
              "      <td>uhnov1</td>\n",
              "      <td>Бинбанк</td>\n",
              "      <td>2015-06-08 12:50:54</td>\n",
              "      <td>Добрый день! Я не являюсь клиентом банка и пор...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>222</td>\n",
              "      <td>1523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>г. Новосибирск</td>\n",
              "      <td>False</td>\n",
              "      <td>Не могу пользоваться услугой Сбербанк он-лайн</td>\n",
              "      <td>0</td>\n",
              "      <td>лицензия № 1481</td>\n",
              "      <td>Foryou</td>\n",
              "      <td>Сбербанк России</td>\n",
              "      <td>2015-06-08 11:09:57</td>\n",
              "      <td>Доброго дня! Являюсь держателем зарплатной кар...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>136</td>\n",
              "      <td>1026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>г. Москва</td>\n",
              "      <td>False</td>\n",
              "      <td>Двойное списание за один товар.</td>\n",
              "      <td>1</td>\n",
              "      <td>лицензия № 2562</td>\n",
              "      <td>Vladimir84</td>\n",
              "      <td>Бинбанк</td>\n",
              "      <td>2015-06-05 20:14:28</td>\n",
              "      <td>Здравствуйте!  Дублирую свое заявление от 03.0...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>93</td>\n",
              "      <td>588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>г. Ставрополь</td>\n",
              "      <td>False</td>\n",
              "      <td>Меняют проценты комиссии  не предупредив и не ...</td>\n",
              "      <td>2</td>\n",
              "      <td>лицензия № 1481</td>\n",
              "      <td>643609</td>\n",
              "      <td>Сбербанк России</td>\n",
              "      <td>2015-06-05 13:51:01</td>\n",
              "      <td>Добрый день!! Я открыл расчетный счет в СберБа...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>124</td>\n",
              "      <td>740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>г. Челябинск</td>\n",
              "      <td>False</td>\n",
              "      <td>Верните денежные средства за страховку</td>\n",
              "      <td>1</td>\n",
              "      <td>лицензия № 2766</td>\n",
              "      <td>anfisa-2003</td>\n",
              "      <td>ОТП Банк</td>\n",
              "      <td>2015-06-05 10:58:12</td>\n",
              "      <td>04.03.2015 г. взяла кредит в вашем банке, заяв...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>308</td>\n",
              "      <td>1896</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             city  rating_not_checked  \\\n",
              "0       г. Москва               False   \n",
              "1  г. Новосибирск               False   \n",
              "2       г. Москва               False   \n",
              "3   г. Ставрополь               False   \n",
              "4    г. Челябинск               False   \n",
              "\n",
              "                                               title  num_comments  \\\n",
              "0                                             Жалоба             0   \n",
              "1      Не могу пользоваться услугой Сбербанк он-лайн             0   \n",
              "2                    Двойное списание за один товар.             1   \n",
              "3  Меняют проценты комиссии  не предупредив и не ...             2   \n",
              "4             Верните денежные средства за страховку             1   \n",
              "\n",
              "      bank_license       author        bank_name             datetime  \\\n",
              "0  лицензия № 2562       uhnov1          Бинбанк  2015-06-08 12:50:54   \n",
              "1  лицензия № 1481       Foryou  Сбербанк России  2015-06-08 11:09:57   \n",
              "2  лицензия № 2562   Vladimir84          Бинбанк  2015-06-05 20:14:28   \n",
              "3  лицензия № 1481       643609  Сбербанк России  2015-06-05 13:51:01   \n",
              "4  лицензия № 2766  anfisa-2003         ОТП Банк  2015-06-05 10:58:12   \n",
              "\n",
              "                                                text  rating_grade  \\\n",
              "0  Добрый день! Я не являюсь клиентом банка и пор...           NaN   \n",
              "1  Доброго дня! Являюсь держателем зарплатной кар...           NaN   \n",
              "2  Здравствуйте!  Дублирую свое заявление от 03.0...           NaN   \n",
              "3  Добрый день!! Я открыл расчетный счет в СберБа...           NaN   \n",
              "4  04.03.2015 г. взяла кредит в вашем банке, заяв...           NaN   \n",
              "\n",
              "   words_counter  symbols_counter  \n",
              "0            222             1523  \n",
              "1            136             1026  \n",
              "2             93              588  \n",
              "3            124              740  \n",
              "4            308             1896  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "S1ERmR3J-3B9",
        "outputId": "59c2a45d-aea4-403f-a802-18c791569650"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df.symbols_counter.hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "jUd6cZY2-3EH",
        "outputId": "3a2c5db2-3d83-481a-abbc-e44c891ce7ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df.words_counter.hist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uo1UHIaIRVAb"
      },
      "source": [
        "3. Найдите 10 самых частых:\n",
        "  * слов\n",
        "  * слов без стоп-слов\n",
        "  * лемм\n",
        "  * существительных\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGkMxrsIpngv",
        "outputId": "717d6a4c-7b03-4d55-a38c-186c3c797415"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Suile\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUJe0if8pngv",
        "outputId": "6087987a-cd0c-4dfa-bb12-c22b01675d3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
            "Requirement already satisfied: pymystem3 in c:\\users\\suile\\anaconda3\\lib\\site-packages (0.2.0)\n",
            "Requirement already satisfied: requests in c:\\users\\suile\\anaconda3\\lib\\site-packages (from pymystem3) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\suile\\anaconda3\\lib\\site-packages (from requests->pymystem3) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\suile\\anaconda3\\lib\\site-packages (from requests->pymystem3) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\suile\\anaconda3\\lib\\site-packages (from requests->pymystem3) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\suile\\anaconda3\\lib\\site-packages (from requests->pymystem3) (2023.11.17)\n"
          ]
        }
      ],
      "source": [
        "!pip install pymystem3\n",
        "from pymystem3 import Mystem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0R21rdipngv",
        "outputId": "39cd6dcf-e91d-4719-9eb3-1909a158511f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "     ---------------------------------------- 0.0/55.5 kB ? eta -:--:--\n",
            "     -------------- ----------------------- 20.5/55.5 kB 330.3 kB/s eta 0:00:01\n",
            "     -------------------------------------- 55.5/55.5 kB 580.0 kB/s eta 0:00:00\n",
            "Collecting dawg-python>=0.7.1 (from pymorphy2)\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4 (from pymorphy2)\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "     ---------------------------------------- 0.0/8.2 MB ? eta -:--:--\n",
            "     ---------------------------------------- 0.1/8.2 MB 1.7 MB/s eta 0:00:05\n",
            "     - -------------------------------------- 0.3/8.2 MB 3.4 MB/s eta 0:00:03\n",
            "     -- ------------------------------------- 0.6/8.2 MB 4.5 MB/s eta 0:00:02\n",
            "     ------ --------------------------------- 1.4/8.2 MB 8.0 MB/s eta 0:00:01\n",
            "     ------------ --------------------------- 2.6/8.2 MB 11.8 MB/s eta 0:00:01\n",
            "     ------------------ --------------------- 3.8/8.2 MB 13.4 MB/s eta 0:00:01\n",
            "     ------------------------ --------------- 5.1/8.2 MB 15.5 MB/s eta 0:00:01\n",
            "     ----------------------------- ---------- 6.0/8.2 MB 15.9 MB/s eta 0:00:01\n",
            "     ---------------------------------- ----- 7.1/8.2 MB 16.8 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 8.2/8.2 MB 18.1 MB/s eta 0:00:00\n",
            "Collecting docopt>=0.6 (from pymorphy2)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Building wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py): started\n",
            "  Building wheel for docopt (setup.py): finished with status 'done'\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13775 sha256=1530fe183cdeb44dee4f1a0fc065a69b81391fd3ae6b86d423d15772e0842cd3\n",
            "  Stored in directory: C:\\Users\\Suile\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-gmd43abq\\wheels\\1a\\b0\\8c\\4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
            "Successfully built docopt\n",
            "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ]
        }
      ],
      "source": [
        "!pip install pymorphy2\n",
        "from pymorphy2 import MorphAnalyzer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZXqSMXWpngv"
      },
      "outputs": [],
      "source": [
        "def pymorphy2_311_hotfix():\n",
        "    from inspect import getfullargspec\n",
        "    from pymorphy2.units.base import BaseAnalyzerUnit\n",
        "\n",
        "    def _get_param_names_311(klass):\n",
        "        if klass.__init__ is object.__init__:\n",
        "            return []\n",
        "        args = getfullargspec(klass.__init__).args\n",
        "        return sorted(args[1:])\n",
        "\n",
        "    setattr(BaseAnalyzerUnit, '_get_param_names', _get_param_names_311)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtrYZqGppngv"
      },
      "outputs": [],
      "source": [
        "pymorphy2_311_hotfix()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bbSe8QLpngv",
        "outputId": "fc5b50fe-0147-4937-c581-c2c12d712723"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.11.5\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFhMn0xrpngw"
      },
      "source": [
        "т.к. не хватает памяти на токенизацию за один раз, то делаем это итерациями"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VTyFI0Kpngw"
      },
      "outputs": [],
      "source": [
        "def word_counter(df):\n",
        "    n = 10_000\n",
        "    max_n = len(df)\n",
        "    counter_dict = dict()\n",
        "    vec = CountVectorizer()\n",
        "\n",
        "    while n <= max_n:\n",
        "        bow = vec.fit_transform(df.iloc[n-10_000:n].text)\n",
        "\n",
        "        word_list = vec.get_feature_names_out()\n",
        "        count_list = bow.toarray().sum(axis=0)\n",
        "\n",
        "        for x, y in zip(word_list, count_list):\n",
        "            if (x in counter_dict):\n",
        "                counter_dict[x] += y\n",
        "            else:\n",
        "                counter_dict[x] = y\n",
        "\n",
        "        print(n)\n",
        "        if n == max_n:\n",
        "            break\n",
        "        n = n + 10_000 if n < max_n else max_n\n",
        "\n",
        "    return counter_dict\n",
        "\n",
        "def word_counter_without_stopwords(df):\n",
        "    n = 10_000\n",
        "    max_n = len(df)\n",
        "    counter_dict = dict()\n",
        "    vec = CountVectorizer()\n",
        "\n",
        "    while n <= max_n:\n",
        "        bow = vec.fit_transform(df.iloc[n-10_000:n].text)\n",
        "\n",
        "        word_list = vec.get_feature_names_out()\n",
        "        count_list = bow.toarray().sum(axis=0)\n",
        "\n",
        "        for x, y in zip(word_list, count_list):\n",
        "            if x in stopwords.words('russian'):\n",
        "                continue\n",
        "            if (x in counter_dict):\n",
        "                counter_dict[x] += y\n",
        "            else:\n",
        "                counter_dict[x] = y\n",
        "\n",
        "        print(n)\n",
        "        if n == max_n:\n",
        "            break\n",
        "        n = n + 10_000 if n < max_n else max_n\n",
        "\n",
        "    return counter_dict\n",
        "\n",
        "def lemm_counter_without_stopwords(df, noun=False):\n",
        "    n = 10_000\n",
        "    max_n = len(df)\n",
        "    counter_dict = dict()\n",
        "    vec = CountVectorizer()\n",
        "    pymorphy2_analyzer = MorphAnalyzer()\n",
        "\n",
        "    while n <= max_n:\n",
        "        bow = vec.fit_transform(df.iloc[n-10_000:n].text)\n",
        "\n",
        "        word_list = vec.get_feature_names_out()\n",
        "        count_list = bow.toarray().sum(axis=0)\n",
        "\n",
        "        for x, y in zip(word_list, count_list):\n",
        "            lemma = pymorphy2_analyzer.parse(x)[0]\n",
        "            key = lemma.normal_form\n",
        "            if noun:\n",
        "                if 'NOUN' in lemma.tag:\n",
        "                    if key in stopwords.words('russian'):\n",
        "                        continue\n",
        "                    if (key in counter_dict):\n",
        "                        counter_dict[key] += y\n",
        "                    else:\n",
        "                        counter_dict[key] = y\n",
        "            else:\n",
        "                if key in stopwords.words('russian'):\n",
        "                    continue\n",
        "                if (key in counter_dict):\n",
        "                    counter_dict[key] += y\n",
        "                else:\n",
        "                    counter_dict[key] = y\n",
        "\n",
        "        print(n)\n",
        "        if n == max_n:\n",
        "            break\n",
        "        n = n + 10_000 if n < max_n else max_n\n",
        "\n",
        "    return counter_dict\n",
        "\n",
        "regex = re.compile(\"[А-Яа-я]+\")\n",
        "\n",
        "def my_lemmatize(text):\n",
        "    pymorphy2_analyzer = MorphAnalyzer()\n",
        "\n",
        "    try:\n",
        "        return \" \".join([pymorphy2_analyzer.parse(token)[0].normal_form for token in \" \".join(regex.findall(text)).split() if not token in stopwords.words('russian')])\n",
        "    except:\n",
        "        return \"\"\n",
        "\n",
        "def add_lemms(df):\n",
        "    iter_k = 10_000\n",
        "    n = 10_000\n",
        "    copy_df = df.copy()\n",
        "    max_n = len(copy_df)\n",
        "    tmp_df = None\n",
        "    total_df = None\n",
        "\n",
        "    while n <= max_n:\n",
        "        tmp_df = copy_df.iloc[n-iter_k:n].text.str.lower().apply(my_lemmatize).to_frame()\n",
        "\n",
        "        if total_df is None:\n",
        "            total_df = tmp_df.copy()\n",
        "            total_df.to_csv('lemma_df_out_{}.csv'.format(n))\n",
        "        else:\n",
        "            total_df = pd.concat([total_df, tmp_df], ignore_index=True)\n",
        "            total_df.to_csv('lemma_df_out_{}.csv'.format(n))\n",
        "\n",
        "        print(n)\n",
        "        gc.collect()\n",
        "        if n == max_n:\n",
        "            break\n",
        "\n",
        "        n = n + iter_k if n + iter_k < max_n else max_n\n",
        "\n",
        "    return total_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_oV9_QCpngw",
        "outputId": "1b9f5275-98e7-4a40-f729-20e637b78b07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10000\n",
            "20000\n",
            "30000\n",
            "40000\n",
            "50000\n",
            "60000\n",
            "70000\n",
            "80000\n",
            "90000\n",
            "100000\n",
            "110000\n",
            "120000\n",
            "130000\n",
            "140000\n",
            "150000\n"
          ]
        }
      ],
      "source": [
        "words = word_counter(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6DhflSbpngw"
      },
      "source": [
        "топ 10 слов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qEgY9Hipngw",
        "outputId": "40d9e81b-31c3-447b-ac60-032cbe92526f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "не 840632\n",
            "на 698119\n",
            "что 631817\n",
            "по 368029\n",
            "мне 317448\n",
            "банка 273159\n",
            "банк 212480\n",
            "как 202625\n",
            "но 197070\n",
            "за 189398\n"
          ]
        }
      ],
      "source": [
        "for word in sorted(words, key=words.get, reverse=True)[:10]:\n",
        "    print(word, words[word])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hpHUoTBpngx"
      },
      "source": [
        "топ 10 слов без стоп слов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQHcOBe_RGcU",
        "outputId": "42461cba-5225-403a-8b9f-d59d969846f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10000\n",
            "20000\n",
            "30000\n",
            "40000\n",
            "50000\n",
            "60000\n",
            "70000\n",
            "80000\n",
            "90000\n",
            "100000\n",
            "110000\n",
            "120000\n",
            "130000\n",
            "140000\n",
            "150000\n"
          ]
        }
      ],
      "source": [
        "words_without_stopwords = word_counter_without_stopwords(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kl9ztVMRGez",
        "outputId": "b725546a-229a-42f8-84e7-7246c28130bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "банка 273159\n",
            "банк 212480\n",
            "это 180295\n",
            "деньги 129499\n",
            "карту 104427\n",
            "карты 100865\n",
            "кредит 79411\n",
            "день 75708\n",
            "банке 71068\n",
            "заявление 69833\n"
          ]
        }
      ],
      "source": [
        "for word in sorted(words_without_stopwords, key=words_without_stopwords.get, reverse=True)[:10]:\n",
        "    print(word, words_without_stopwords[word])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s47M_dwXRGhF",
        "outputId": "b72b9071-f2d0-4196-ecb3-020eaecd4283"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10000\n",
            "20000\n",
            "30000\n",
            "40000\n",
            "50000\n",
            "60000\n",
            "70000\n",
            "80000\n",
            "90000\n",
            "100000\n",
            "110000\n",
            "120000\n",
            "130000\n",
            "140000\n",
            "150000\n"
          ]
        }
      ],
      "source": [
        "lemms_without_stopwords = lemm_counter_without_stopwords(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6Z2q8bTpngx"
      },
      "source": [
        "топ 10 лемм без стоп слов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpWauGskRGjL",
        "outputId": "9283e80e-98d9-4105-c64a-dab2867aad55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "банк 660069\n",
            "карта 331167\n",
            "это 303745\n",
            "всё 196630\n",
            "деньга 177419\n",
            "день 171421\n",
            "кредит 153089\n",
            "который 147132\n",
            "отделение 142199\n",
            "счёт 140594\n"
          ]
        }
      ],
      "source": [
        "for word in sorted(lemms_without_stopwords, key=lemms_without_stopwords.get, reverse=True)[:10]:\n",
        "    print(word, lemms_without_stopwords[word])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlfTfu91RGn7",
        "outputId": "ac2f1bb7-79ee-43f1-d0a0-0fbdcd195509"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10000\n",
            "20000\n",
            "30000\n",
            "40000\n",
            "50000\n",
            "60000\n",
            "70000\n",
            "80000\n",
            "90000\n",
            "100000\n",
            "110000\n",
            "120000\n",
            "130000\n",
            "140000\n",
            "150000\n"
          ]
        }
      ],
      "source": [
        "noun_lemms_without_stopwords = lemm_counter_without_stopwords(df, noun=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1yk7-jdpng1",
        "outputId": "a7f60be4-366f-4d31-f54b-be597f2be1bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10000\n",
            "20000\n",
            "30000\n",
            "40000\n",
            "50000\n",
            "60000\n",
            "70000\n",
            "80000\n",
            "90000\n",
            "100000\n",
            "110000\n",
            "120000\n",
            "130000\n",
            "140000\n",
            "150000\n",
            "153499\n"
          ]
        }
      ],
      "source": [
        "df_with_lems = add_lemms(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiXFX57apng1"
      },
      "source": [
        "топ 10 лемм существительных без стоп слов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7Hu7NaGpng1",
        "outputId": "ee0847da-3bac-425c-fd05-d6a1b162168c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "банк 660069\n",
            "карта 331167\n",
            "деньга 177419\n",
            "день 171421\n",
            "кредит 153089\n",
            "отделение 142199\n",
            "счёт 140594\n",
            "клиент 134888\n",
            "сотрудник 133031\n",
            "сумма 109975\n"
          ]
        }
      ],
      "source": [
        "for word in sorted(noun_lemms_without_stopwords, key=noun_lemms_without_stopwords.get, reverse=True)[:10]:\n",
        "    print(word, noun_lemms_without_stopwords[word])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMSXpK_Ipng1"
      },
      "source": [
        "#### 4. Постройте кривые Ципфа и Хипса"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiNC6kJkpng1"
      },
      "source": [
        "Кривая Ципфа"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfDbSoLgpng1",
        "outputId": "ed5a0222-81c5-4a2b-c3b3-0464443190e2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "freqs = list(noun_lemms_without_stopwords.values())\n",
        "freqs = sorted(freqs, reverse = True)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(freqs[:300], range(300))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAC1mXMbpng2"
      },
      "source": [
        "Крифая Хипса"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMGvDg9Bpng2"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "def lemm_tokenize_without_stopwords(df, noun=False):\n",
        "    k = 5_000\n",
        "    n = 5_000\n",
        "    max_n = len(df)\n",
        "    counter_dict = dict()\n",
        "    vec = CountVectorizer()\n",
        "    pymorphy2_analyzer = MorphAnalyzer()\n",
        "    n_words = []\n",
        "    n_tokens = []\n",
        "\n",
        "    while n <= max_n:\n",
        "        bow = vec.fit_transform(df.iloc[n-k:n].text)\n",
        "\n",
        "        word_list = vec.get_feature_names_out()\n",
        "        count_list = bow.toarray()\n",
        "\n",
        "        for row in count_list:\n",
        "            for i, elem in enumerate(row):\n",
        "                if elem:\n",
        "                    lemma = pymorphy2_analyzer.parse(word_list[i])[0]\n",
        "                    key = lemma.normal_form\n",
        "                    if noun:\n",
        "                        if 'NOUN' in lemma.tag:\n",
        "                            if key in stopwords.words('russian'):\n",
        "                                continue\n",
        "                            if (key in counter_dict):\n",
        "                                counter_dict[key] += elem\n",
        "                            else:\n",
        "                                counter_dict[key] = elem\n",
        "                    else:\n",
        "                        if key in stopwords.words('russian'):\n",
        "                            continue\n",
        "                        if (key in counter_dict):\n",
        "                            counter_dict[key] += elem\n",
        "                        else:\n",
        "                            counter_dict[key] = elem\n",
        "\n",
        "        n_words.append(len(counter_dict.keys()))\n",
        "        n_tokens.append(sum(list(counter_dict.values())))\n",
        "        gc.collect()\n",
        "\n",
        "        print(\"n_words: {}\".format(n_words[-1]))\n",
        "        print(\"n_tokens: {}\".format(n_tokens[-1]))\n",
        "\n",
        "        print(n)\n",
        "        if n == max_n:\n",
        "            break\n",
        "        n = n + k if n < max_n else max_n\n",
        "\n",
        "    return (n_words, n_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geH3wJIepng2",
        "outputId": "29cd6b40-c3a2-4aeb-e031-f58e8fe14b4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n_words: 8673\n",
            "n_tokens: 310665\n",
            "5000\n",
            "n_words: 12269\n",
            "n_tokens: 630591\n",
            "10000\n",
            "n_words: 14935\n",
            "n_tokens: 947565\n",
            "15000\n",
            "n_words: 17235\n",
            "n_tokens: 1266155\n",
            "20000\n",
            "n_words: 19251\n",
            "n_tokens: 1575549\n",
            "25000\n",
            "n_words: 21061\n",
            "n_tokens: 1904627\n",
            "30000\n",
            "n_words: 22810\n",
            "n_tokens: 2248287\n",
            "35000\n",
            "n_words: 24409\n",
            "n_tokens: 2581821\n",
            "40000\n",
            "n_words: 25919\n",
            "n_tokens: 2901624\n",
            "45000\n",
            "n_words: 27383\n",
            "n_tokens: 3233901\n",
            "50000\n",
            "n_words: 28766\n",
            "n_tokens: 3568061\n",
            "55000\n",
            "n_words: 30178\n",
            "n_tokens: 3908264\n",
            "60000\n",
            "n_words: 31552\n",
            "n_tokens: 4244772\n",
            "65000\n",
            "n_words: 32993\n",
            "n_tokens: 4595878\n",
            "70000\n",
            "n_words: 34260\n",
            "n_tokens: 4938211\n",
            "75000\n",
            "n_words: 35547\n",
            "n_tokens: 5288730\n",
            "80000\n",
            "n_words: 36803\n",
            "n_tokens: 5643605\n",
            "85000\n",
            "n_words: 37991\n",
            "n_tokens: 6001354\n",
            "90000\n",
            "n_words: 39233\n",
            "n_tokens: 6359764\n",
            "95000\n",
            "n_words: 40498\n",
            "n_tokens: 6734416\n",
            "100000\n",
            "n_words: 41843\n",
            "n_tokens: 7101046\n",
            "105000\n",
            "n_words: 42918\n",
            "n_tokens: 7460269\n",
            "110000\n",
            "n_words: 44186\n",
            "n_tokens: 7843963\n",
            "115000\n",
            "n_words: 45498\n",
            "n_tokens: 8235693\n",
            "120000\n",
            "n_words: 46716\n",
            "n_tokens: 8633636\n",
            "125000\n",
            "n_words: 47939\n",
            "n_tokens: 9025665\n",
            "130000\n",
            "n_words: 49168\n",
            "n_tokens: 9417763\n",
            "135000\n",
            "n_words: 50480\n",
            "n_tokens: 9764132\n",
            "140000\n",
            "n_words: 51684\n",
            "n_tokens: 10099682\n",
            "145000\n",
            "n_words: 52891\n",
            "n_tokens: 10420622\n",
            "150000\n"
          ]
        }
      ],
      "source": [
        "n_words, n_tokens = lemm_tokenize_without_stopwords(df, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RA7tgVnYpng2",
        "outputId": "2c304dd8-b95b-40d4-db13-94ae82e436a0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(n_tokens, n_words)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nstL3YQCpng2"
      },
      "source": [
        "Ответьте на следующие вопросы:\n",
        "* какое слово встречается чаще, \"сотрудник\" или \"клиент\"?\n",
        "* сколько раз встречается слова \"мошенничество\" и \"доверие\"?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vf89yp3bpng2"
      },
      "source": [
        "Слово \"клиент\" встречается чаще чем \"сотрудник\"\n",
        "\n",
        "Слово \"мошенничество\" - 3225\n",
        "\n",
        "Слово \"доверие\" - 2086"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siIFbWPSpng3",
        "outputId": "98f1689f-f340-4702-e5f2-e71199da81be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "сотрудник: 133031 -- клиент: 134888\n",
            "мошенничество: 3225 -- доверие: 2086\n"
          ]
        }
      ],
      "source": [
        "print(\"сотрудник: {} -- клиент: {}\".format(noun_lemms_without_stopwords[\"сотрудник\"], noun_lemms_without_stopwords[\"клиент\"]))\n",
        "print(\"мошенничество: {} -- доверие: {}\".format(noun_lemms_without_stopwords[\"мошенничество\"], noun_lemms_without_stopwords[\"доверие\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbo36iIrpng3"
      },
      "source": [
        "В поле \"rating_grade\" записана оценка отзыва по шкале от 1 до 5. Используйте меру\n",
        ", для того, чтобы найти ключевые слова и биграмы для положительных отзывов (с оценкой 5) и отрицательных отзывов (с оценкой 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5jq5iaEpng3"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBlrqDcWpng3",
        "outputId": "97787185-e023-433f-d70f-10d38d383a6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14713\n",
            "47387\n"
          ]
        }
      ],
      "source": [
        "print(len(df[df['rating_grade'] == 5]))\n",
        "print(len(df[df['rating_grade'] == 1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jsogQXfpng3"
      },
      "outputs": [],
      "source": [
        "def tfidf_vectorizer(df, ngrams=(1,1), grade=1):\n",
        "    n = 5_000\n",
        "    tmp_df = df[df['rating_grade'] == grade]\n",
        "    max_n = len(tmp_df)\n",
        "    counter_dict = dict()\n",
        "    vec = TfidfVectorizer(ngram_range=ngrams)\n",
        "    pymorphy2_analyzer = MorphAnalyzer()\n",
        "\n",
        "    while n <= max_n:\n",
        "        k = len(tmp_df.iloc[n-5_000:n])\n",
        "        bow = vec.fit_transform(tmp_df.iloc[n-5_000:n].text)\n",
        "\n",
        "        feature_names = vec.get_feature_names_out()\n",
        "        tfidf_scores = bow.toarray().sum(axis=0)\n",
        "\n",
        "        for x, y in zip(feature_names, tfidf_scores):\n",
        "            lemma = pymorphy2_analyzer.parse(x)[0]\n",
        "            key = lemma.normal_form\n",
        "\n",
        "            if 'NOUN' in lemma.tag:\n",
        "                if key in stopwords.words('russian'):\n",
        "                    continue\n",
        "                if (key in counter_dict):\n",
        "                    counter_dict[key] += y / k\n",
        "                else:\n",
        "                    counter_dict[key] = y / k\n",
        "\n",
        "        print(n)\n",
        "        gc.collect()\n",
        "        if n == max_n:\n",
        "            break\n",
        "\n",
        "        n = n + 5_000 if n + 5_000 < max_n else max_n\n",
        "\n",
        "    return counter_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sb9it_shpng4",
        "outputId": "24898a01-e485-4ae1-818e-39f415418ea0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Топ 10 слов с оценкой 5\n",
            "банк : 0.22760663186441424\n",
            "карта : 0.12177994912122492\n",
            "клиент : 0.08294653544358484\n",
            "вклад : 0.0814982745671285\n",
            "кредит : 0.0779622347975636\n",
            "сотрудник : 0.0757208678481325\n",
            "отделение : 0.07559750229672599\n",
            "день : 0.06876043236609516\n",
            "вопрос : 0.06320653291412313\n",
            "счёт : 0.06300129230435333\n"
          ]
        }
      ],
      "source": [
        "positive_grade_word_tfidf = tfidf_vectorizer(df, grade=5)\n",
        "top_words = []\n",
        "\n",
        "print(\"Топ 10 слов с оценкой 5\")\n",
        "for word in sorted(positive_grade_word_tfidf, key=positive_grade_word_tfidf.get, reverse=True)[:10]:\n",
        "    print(\"{} : {}\".format(word, positive_grade_word_tfidf[word]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPxgiNoDpng4",
        "outputId": "0476b47b-f7e3-4dc6-e97c-e9b65c3ce8f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5000\n",
            "10000\n",
            "14713\n",
            "Топ 10 биграм с оценкой 5\n",
            "на счёт : 0.014390543872726718\n",
            "что ич : 0.01365038971858018\n",
            "интернет банк : 0.012686557054053853\n",
            "на сайт : 0.01189970145182749\n",
            "по телефон : 0.011351711045830612\n",
            "банка ич : 0.011200686660685227\n",
            "на карта : 0.010763242243176218\n",
            "альфа банк : 0.010672619669302148\n",
            "по вклад : 0.010382508775641886\n",
            "мне ич : 0.009654636699801301\n"
          ]
        }
      ],
      "source": [
        "positive_grade_bigram_tfidf = tfidf_vectorizer(df, grade=5, ngrams=(2,2))\n",
        "top_words = []\n",
        "\n",
        "print(\"Топ 10 биграм с оценкой 5\")\n",
        "for word in sorted(positive_grade_bigram_tfidf, key=positive_grade_bigram_tfidf.get, reverse=True)[:10]:\n",
        "    print(\"{} : {}\".format(word, positive_grade_bigram_tfidf[word]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWrAZPScpng4",
        "outputId": "dca2d905-7ae0-476b-be0c-737d7608d0dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5000\n",
            "10000\n",
            "15000\n",
            "20000\n",
            "25000\n",
            "30000\n",
            "35000\n",
            "40000\n",
            "45000\n",
            "47387\n",
            "Топ 10 слов с оценкой 1\n",
            "банк : 0.9766455465815853\n",
            "карта : 0.7052020740512581\n",
            "счёт : 0.4131200797814096\n",
            "день : 0.40897867665729676\n",
            "кредит : 0.3915145420914679\n",
            "деньга : 0.39045322515940845\n",
            "отделение : 0.38707398695801054\n",
            "клиент : 0.3828504707368051\n",
            "сотрудник : 0.38129262335259273\n",
            "заявление : 0.294362960322143\n"
          ]
        }
      ],
      "source": [
        "negative_grade_word_tfidf = tfidf_vectorizer(df, grade=1)\n",
        "top_words = []\n",
        "\n",
        "print(\"Топ 10 слов с оценкой 1\")\n",
        "for word in sorted(negative_grade_word_tfidf, key=negative_grade_word_tfidf.get, reverse=True)[:10]:\n",
        "    print(\"{} : {}\".format(word, negative_grade_word_tfidf[word]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0mz1RrOpng4",
        "outputId": "7ea73772-f7f3-4bdc-efd2-2ce07003c2a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5000\n",
            "10000\n",
            "15000\n",
            "20000\n",
            "25000\n",
            "30000\n",
            "35000\n",
            "40000\n",
            "45000\n",
            "47387\n",
            "Топ 10 биграм с оценкой 1\n",
            "на счёт : 0.07424958076280819\n",
            "что ич : 0.06087194380655993\n",
            "деньги ич : 0.05487437389915594\n",
            "на сайт : 0.054116122916975186\n",
            "по телефон : 0.05119285970585724\n",
            "на карта : 0.05039674850998286\n",
            "мне ич : 0.047268535457104424\n",
            "банка ич : 0.04714091038680225\n",
            "заявление ич : 0.0442987974350318\n",
            "ничего ич : 0.04338621318391671\n"
          ]
        }
      ],
      "source": [
        "negative_grade_bigram_tfidf = tfidf_vectorizer(df, grade=1, ngrams=(2,2))\n",
        "top_words = []\n",
        "\n",
        "print(\"Топ 10 биграм с оценкой 1\")\n",
        "for word in sorted(negative_grade_bigram_tfidf, key=negative_grade_bigram_tfidf.get, reverse=True)[:10]:\n",
        "    print(\"{} : {}\".format(word, negative_grade_bigram_tfidf[word]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4uTL1f53KJF"
      },
      "source": [
        "#### Thematic modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m54zGo3Rpng4"
      },
      "source": [
        "1. Постройте несколько тематических моделей коллекции документов с разным числом тем. Приведите примеры понятных (интерпретируемых) тем.\n",
        "2. Найдите темы, в которых упомянуты конкретные банки (Сбербанк, ВТБ, другой банк). Можете ли вы их прокомментировать / объяснить? Эта часть задания может быть сделана с использованием gensim."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-m6PVKY3Yne"
      },
      "outputs": [],
      "source": [
        "import gensim.corpora as corpora\n",
        "from gensim.models import ldamodel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtddYVuZpng5",
        "outputId": "0b54ed45-e6f1-46ad-de51-f8b4f9a400b5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>добрый день являться клиент банк поручитель кр...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>добрый день являться держатель зарплатный карт...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>здравствуйте дублировать свой заявление можайс...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>добрый день открыть расчётный счёт сбербанк юр...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>г взять кредит ваш банк заявить я сумма так ру...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  добрый день являться клиент банк поручитель кр...\n",
              "1  добрый день являться держатель зарплатный карт...\n",
              "2  здравствуйте дублировать свой заявление можайс...\n",
              "3  добрый день открыть расчётный счёт сбербанк юр...\n",
              "4  г взять кредит ваш банк заявить я сумма так ру..."
            ]
          },
          "execution_count": 386,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_with_lems.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8k0o_R63dT1"
      },
      "outputs": [],
      "source": [
        "texts = [df_with_lems['text'].iloc[i].split() for i in range(len(df_with_lems))]\n",
        "dictionary = corpora.Dictionary(texts)\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "random.seed(11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeV1kzwc3dV1"
      },
      "outputs": [],
      "source": [
        "lda = ldamodel.LdaModel(corpus=corpus,\n",
        "                        id2word=dictionary,\n",
        "                        num_topics=20,\n",
        "                        alpha='auto',\n",
        "                        eta='auto',\n",
        "                        iterations = 20,\n",
        "                        passes = 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbxPM20o3Yp1",
        "outputId": "d82dea73-c2f3-41c6-8822-05b29da6dda0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.058*\"доллар\" + 0.057*\"курс\" + 0.041*\"евро\" + 0.039*\"валюта\" + 0.038*\"рубль\" + 0.022*\"валютный\" + 0.020*\"сумма\" + 0.020*\"кассир\" + 0.020*\"юниаструма\" + 0.018*\"рублёвый\"'),\n",
              " (11,\n",
              "  '0.050*\"мы\" + 0.029*\"наш\" + 0.028*\"муж\" + 0.020*\"жена\" + 0.019*\"год\" + 0.014*\"ребёнок\" + 0.014*\"мама\" + 0.013*\"платить\" + 0.012*\"суд\" + 0.009*\"человек\"'),\n",
              " (6,\n",
              "  '0.021*\"это\" + 0.016*\"так\" + 0.014*\"вс\" + 0.011*\"тот\" + 0.009*\"быть\" + 0.008*\"ещ\" + 0.006*\"общий\" + 0.006*\"думать\" + 0.006*\"сч\" + 0.006*\"один\"'),\n",
              " (1,\n",
              "  '0.027*\"сказать\" + 0.021*\"день\" + 0.019*\"это\" + 0.018*\"звонить\" + 0.017*\"банк\" + 0.017*\"позвонить\" + 0.017*\"говорить\" + 0.012*\"мочь\" + 0.011*\"девушка\" + 0.010*\"телефон\"'),\n",
              " (18,\n",
              "  '0.086*\"банк\" + 0.031*\"клиент\" + 0.021*\"очень\" + 0.019*\"это\" + 0.015*\"свой\" + 0.014*\"сотрудник\" + 0.014*\"который\" + 0.011*\"такой\" + 0.011*\"вопрос\" + 0.010*\"работа\"')]"
            ]
          },
          "execution_count": 389,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lda.show_topics(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkB2pc6upng5"
      },
      "source": [
        "Вторая тема из выборки выше возможно следующая: \"Жена подала в суд на мужа из-за невыплат за годовалого ребенка\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_cT0Zn93YsH"
      },
      "outputs": [],
      "source": [
        "lda15 = ldamodel.LdaModel(corpus=corpus,\n",
        "                          id2word=dictionary,\n",
        "                          num_topics=15,\n",
        "                          alpha='auto',\n",
        "                          eta='auto',\n",
        "                          iterations = 20,\n",
        "                          passes = 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWLrysoApng6",
        "outputId": "32bc8353-443a-4568-f12c-9d185c2eaede"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(7,\n",
              "  '0.092*\"альфа\" + 0.073*\"услуга\" + 0.067*\"смс\" + 0.045*\"центр\" + 0.044*\"банк\" + 0.031*\"колл\" + 0.029*\"подключить\" + 0.026*\"мобильный\" + 0.023*\"приходить\" + 0.022*\"телефон\"'),\n",
              " (13,\n",
              "  '0.100*\"вклад\" + 0.052*\"счёт\" + 0.042*\"банк\" + 0.036*\"открыть\" + 0.025*\"деньга\" + 0.025*\"процент\" + 0.023*\"депозит\" + 0.022*\"договор\" + 0.018*\"открытие\" + 0.015*\"сумма\"'),\n",
              " (2,\n",
              "  '0.039*\"отделение\" + 0.029*\"очередь\" + 0.019*\"офис\" + 0.017*\"минута\" + 0.017*\"работать\" + 0.017*\"касса\" + 0.012*\"клиент\" + 0.011*\"человек\" + 0.011*\"сотрудник\" + 0.010*\"час\"'),\n",
              " (10,\n",
              "  '0.022*\"это\" + 0.019*\"сказать\" + 0.018*\"деньга\" + 0.016*\"день\" + 0.015*\"банк\" + 0.014*\"говорить\" + 0.012*\"звонить\" + 0.010*\"позвонить\" + 0.009*\"мочь\" + 0.009*\"девушка\"'),\n",
              " (5,\n",
              "  '0.057*\"банк\" + 0.021*\"клиент\" + 0.018*\"очень\" + 0.016*\"это\" + 0.009*\"который\" + 0.009*\"свой\" + 0.009*\"работа\" + 0.008*\"время\" + 0.008*\"год\" + 0.007*\"обслуживание\"')]"
            ]
          },
          "execution_count": 391,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lda15.show_topics(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFUQ8iHKpng6"
      },
      "source": [
        "Первая тема из выборки выше возможно следующая: Колл центр Альфа банка подключает услугу смс информаирования на мобильный телефон\n",
        "Вторая тема из выборки выше возможно следующая: Откройте счет или вклад в нашем банке под выгодный процент за час"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkZ4ybf7png6"
      },
      "outputs": [],
      "source": [
        "lda_test = ldamodel.LdaModel(corpus=corpus,\n",
        "                          id2word=dictionary,\n",
        "                          num_topics=10,\n",
        "                          alpha='auto',\n",
        "                          eval_every=5,\n",
        "                          iterations = 20,\n",
        "                          passes = 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o93B-10ppng6",
        "outputId": "566d95d3-159a-44ac-853a-0e42089e422f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(6,\n",
              "  '0.038*\"банк\" + 0.028*\"договор\" + 0.015*\"счёт\" + 0.011*\"клиент\" + 0.009*\"который\" + 0.009*\"средство\" + 0.009*\"документ\" + 0.009*\"право\" + 0.009*\"лицо\" + 0.008*\"рф\"'),\n",
              " (8,\n",
              "  '0.070*\"вклад\" + 0.038*\"банк\" + 0.031*\"счёт\" + 0.025*\"открыть\" + 0.024*\"деньга\" + 0.018*\"процент\" + 0.016*\"депозит\" + 0.015*\"админ\" + 0.014*\"сумма\" + 0.013*\"доллар\"'),\n",
              " (9,\n",
              "  '0.029*\"заявление\" + 0.029*\"банк\" + 0.021*\"мой\" + 0.020*\"день\" + 0.019*\"ответ\" + 0.018*\"отделение\" + 0.017*\"г\" + 0.015*\"сотрудник\" + 0.013*\"претензия\" + 0.012*\"написать\"'),\n",
              " (7,\n",
              "  '0.055*\"банк\" + 0.018*\"клиент\" + 0.015*\"очень\" + 0.013*\"это\" + 0.008*\"год\" + 0.008*\"обслуживание\" + 0.008*\"который\" + 0.008*\"работа\" + 0.007*\"свой\" + 0.007*\"время\"'),\n",
              " (5,\n",
              "  '0.016*\"отделение\" + 0.015*\"это\" + 0.011*\"работать\" + 0.011*\"очередь\" + 0.011*\"минута\" + 0.009*\"сказать\" + 0.009*\"девушка\" + 0.009*\"человек\" + 0.008*\"клиент\" + 0.008*\"время\"')]"
            ]
          },
          "execution_count": 396,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lda_test.show_topics(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpNFOldy3Y0F"
      },
      "source": [
        "#### Text classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uie-iNIVpng6"
      },
      "source": [
        "Сформулируем для простоты задачу бинарной классификации: будем классифицировать на два класса, то есть, различать резко отрицательные отзывы (с оценкой 1) и положительные отзывы (с оценкой 5).\n",
        "\n",
        "1. Составьте обучающее и тестовое множество: выберите из всего набора данных N1 отзывов с оценкой 1 и N2 отзывов с оценкой 5 (значение N1 и N2 – на ваше усмотрение). Используйте sklearn.model_selection.train_test_split для разделения множества отобранных документов на обучающее и тестовое.\n",
        "2. Используйте любой известный вам алгоритм классификации текстов для решения задачи и получите baseline. Сравните разные варианты векторизации текста: использование только униграм, пар или троек слов или с использованием символьных\n",
        "-грам.\n",
        "3. Сравните, как изменяется качество решения задачи при использовании скрытых тем в качестве признаков:\n",
        "    * 1-ый вариант: преобразование (sklearn.feature_extraction.text.TfidfTransformer) и сингулярное разложение (оно же – латентый семантический анализ) (sklearn.decomposition.TruncatedSVD),\n",
        "    * 2-ой вариант: тематические модели LDA (sklearn.decomposition.LatentDirichletAllocation). Используйте accuracy и F-measure для оценки качества классификации.\n",
        "\n",
        "В ноутбуке, размещенном в папке репозитория. написан примерный Pipeline для классификации текстов.\n",
        "\n",
        "Эта часть задания может быть сделана с использованием sklearn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LF93aOuFpng6"
      },
      "source": [
        "Составьте обучающее и тестовое множество: выберите из всего набора данных N1 отзывов с оценкой 1 и N2 отзывов с оценкой 5 (значение N1 и N2 – на ваше усмотрение). Используйте sklearn.model_selection.train_test_split для разделения множества отобранных документов на обучающее и тестовое."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6USDtt1png7"
      },
      "outputs": [],
      "source": [
        "clsf_df = df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BakJbyItpng7"
      },
      "outputs": [],
      "source": [
        "clsf_df['lemms'] = df_with_lems['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRJMssYGpng7",
        "outputId": "198a471d-0392-4045-c9c2-bb0c7b063f0b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1995487"
            ]
          },
          "execution_count": 414,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clsf_df.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXFzgNI1png7"
      },
      "outputs": [],
      "source": [
        "df_1 = clsf_df[clsf_df['rating_grade'] == 1].head(5_000)\n",
        "df_5 = clsf_df[clsf_df['rating_grade'] == 5].head(5_000)\n",
        "clsf_df = pd.concat([df_1, df_5], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eE2LKGEYpng7",
        "outputId": "d2e08210-3e6e-4dd0-a322-4881483680f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "rating_grade\n",
              "1.0    5000\n",
              "5.0    5000\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 417,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clsf_df.rating_grade.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4xhnHHOpng7"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJPk-AN-png8"
      },
      "outputs": [],
      "source": [
        "X = clsf_df['lemms'].values\n",
        "y = clsf_df.rating_grade.values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3J2Gjv2Qpng8"
      },
      "source": [
        "Используйте любой известный вам алгоритм классификации текстов для решения задачи и получите baseline. Сравните разные варианты векторизации текста: использование только униграм, пар или троек слов или с использованием символьных\n",
        "-грам."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2fGzhtOpng8"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oNLYz6Cpng8"
      },
      "outputs": [],
      "source": [
        "clf_vectorized = Pipeline(\n",
        "    [('vect', CountVectorizer()),\n",
        "     ('clf', LogisticRegression())]\n",
        ")\n",
        "\n",
        "params = {\n",
        "    'vect__analyzer': ['word','char'],\n",
        "    'vect__max_df': (0.5, 0.75, 1.0),\n",
        "    'vect__ngram_range': ((1, 1), (2, 2), (3, 3)),\n",
        "    'clf__C': np.logspace(-3, 3, 7),\n",
        "    'clf__penalty': ['l1','l2']\n",
        "}\n",
        "\n",
        "scores=['accuracy', 'f1']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhhYSbiipng8"
      },
      "outputs": [],
      "source": [
        "grid_cv = GridSearchCV(\n",
        "    clf_vectorized,\n",
        "    param_grid=params,\n",
        "    cv=4,\n",
        "    scoring=scores,\n",
        "    refit=scores[0],\n",
        "    n_jobs=-1, # use all processors\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwdsXnOEpng8",
        "outputId": "2691df7e-7d60-44db-cf6c-07af36746db3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 4 folds for each of 252 candidates, totalling 1008 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Suile\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
            "504 fits failed out of a total of 1008.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "504 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Suile\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Suile\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Suile\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 420, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"C:\\Users\\Suile\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Suile\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Suile\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Suile\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.90742857 0.81214286 0.639      0.90957143 0.81214286 0.639\n",
            " 0.908      0.81214286 0.639      0.51257143 0.86128571 0.92828571\n",
            " 0.53485714 0.87571429 0.92742857 0.72157143 0.89014286 0.92457143\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.93785714 0.88671429 0.78885714 0.936      0.88671429 0.78885714\n",
            " 0.93285714 0.88671429 0.78885714 0.51257143 0.87357143 0.93214286\n",
            " 0.53185714 0.89071429 0.93057143 0.721      0.89957143 0.92928571\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.94057143 0.90957143 0.83657143 0.94014286 0.90957143 0.83657143\n",
            " 0.93928571 0.90957143 0.83657143 0.51257143 0.87528571 0.92357143\n",
            " 0.53242857 0.88871429 0.92157143 0.72085714 0.89442857 0.92057143\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.938      0.91328571 0.83314286 0.93685714 0.91328571 0.83314286\n",
            " 0.93757143 0.91328571 0.83314286 0.51257143 0.86871429 0.91514286\n",
            " 0.53242857 0.87728571 0.913      0.72085714 0.89328571 0.91185714\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.93471429 0.91414286 0.83342857 0.93342857 0.91414286 0.83342857\n",
            " 0.93285714 0.91414286 0.83342857 0.51257143 0.86185714 0.91214286\n",
            " 0.53242857 0.87228571 0.909      0.72157143 0.89171429 0.90985714\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.93228571 0.91314286 0.831      0.93171429 0.91314286 0.831\n",
            " 0.932      0.91314286 0.831      0.51257143 0.86128571 0.90914286\n",
            " 0.53242857 0.87185714 0.909      0.72128571 0.89285714 0.90928571\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.93071429 0.91285714 0.82942857 0.93114286 0.91285714 0.82942857\n",
            " 0.93142857 0.91285714 0.82942857 0.51257143 0.86028571 0.90714286\n",
            " 0.53242857 0.87157143 0.90785714 0.72114286 0.89228571 0.91057143]\n",
            "  warnings.warn(\n",
            "C:\\Users\\Suile\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.90773786 0.79119888 0.44806693 0.90972623 0.79119888 0.44806693\n",
            " 0.90804077 0.79119888 0.44806693 0.39167342 0.86024876 0.92882605\n",
            " 0.44203979 0.87584167 0.92808544 0.71648901 0.89041174 0.92513816\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.93839279 0.88522413 0.75767044 0.9365196  0.88522413 0.75767044\n",
            " 0.93334958 0.88522413 0.75767044 0.39167342 0.87390917 0.9323019\n",
            " 0.45672447 0.89119534 0.93057175 0.71559421 0.8995114  0.92925373\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.94067425 0.91035026 0.83510188 0.94028485 0.91035026 0.83510188\n",
            " 0.93944518 0.91035026 0.83510188 0.39167342 0.87554427 0.9233109\n",
            " 0.46000017 0.88829325 0.92103329 0.71517733 0.89385376 0.92004879\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.93788426 0.914376   0.83764754 0.9367721  0.914376   0.83764754\n",
            " 0.93753464 0.914376   0.83764754 0.39167342 0.86832204 0.91471514\n",
            " 0.46016936 0.87659247 0.91210591 0.71533384 0.89241355 0.91081443\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.93442367 0.91542198 0.83972747 0.93315674 0.91542198 0.83972747\n",
            " 0.93256504 0.91542198 0.83972747 0.39167342 0.8612275  0.91159704\n",
            " 0.46016936 0.8710388  0.90796548 0.71602194 0.89110826 0.90859625\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.93187065 0.91461391 0.83830428 0.93135646 0.91461391 0.83830428\n",
            " 0.93159835 0.91461391 0.83830428 0.39167342 0.86055221 0.90843264\n",
            " 0.46016936 0.87047479 0.90791248 0.71622512 0.89238116 0.90783008\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.93023961 0.91438261 0.83728453 0.93069664 0.91438261 0.83728453\n",
            " 0.93098942 0.91438261 0.83728453 0.39167342 0.85953202 0.90627712\n",
            " 0.46016936 0.87024177 0.90645601 0.71545107 0.89177904 0.90928659]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=4,\n",
              "             estimator=Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()),\n",
              "                                       (&#x27;clf&#x27;, LogisticRegression())]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;clf__C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
              "                         &#x27;clf__penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
              "                         &#x27;vect__analyzer&#x27;: [&#x27;word&#x27;, &#x27;char&#x27;],\n",
              "                         &#x27;vect__max_df&#x27;: (0.5, 0.75, 1.0),\n",
              "                         &#x27;vect__ngram_range&#x27;: ((1, 1), (2, 2), (3, 3))},\n",
              "             refit=&#x27;accuracy&#x27;, scoring=[&#x27;accuracy&#x27;, &#x27;f1&#x27;], verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=4,\n",
              "             estimator=Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()),\n",
              "                                       (&#x27;clf&#x27;, LogisticRegression())]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;clf__C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
              "                         &#x27;clf__penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
              "                         &#x27;vect__analyzer&#x27;: [&#x27;word&#x27;, &#x27;char&#x27;],\n",
              "                         &#x27;vect__max_df&#x27;: (0.5, 0.75, 1.0),\n",
              "                         &#x27;vect__ngram_range&#x27;: ((1, 1), (2, 2), (3, 3))},\n",
              "             refit=&#x27;accuracy&#x27;, scoring=[&#x27;accuracy&#x27;, &#x27;f1&#x27;], verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;clf&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=4,\n",
              "             estimator=Pipeline(steps=[('vect', CountVectorizer()),\n",
              "                                       ('clf', LogisticRegression())]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'clf__C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
              "                         'clf__penalty': ['l1', 'l2'],\n",
              "                         'vect__analyzer': ['word', 'char'],\n",
              "                         'vect__max_df': (0.5, 0.75, 1.0),\n",
              "                         'vect__ngram_range': ((1, 1), (2, 2), (3, 3))},\n",
              "             refit='accuracy', scoring=['accuracy', 'f1'], verbose=1)"
            ]
          },
          "execution_count": 431,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_cv.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFEZ_rbjpng8",
        "outputId": "33bfecc1-aa1f-4ae2-ab18-da398bc6a0ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([ 1.28353983,  3.99280524,  5.6537562 ,  1.18722022,  3.81197166,\n",
              "         5.47005504,  1.11873287,  3.83521783,  5.87667817,  1.82451719,\n",
              "         4.04044378,  4.51057822,  2.06422108,  4.01653612,  4.81924719,\n",
              "         2.13405067,  3.69262522,  4.59047407,  1.27384359,  6.66692138,\n",
              "         8.70671713,  1.39277548,  7.38300532,  9.07273614,  1.32296193,\n",
              "         6.25576985,  8.85207707,  1.81564516,  3.90879649,  5.41975605,\n",
              "         2.14227074,  3.71132576,  5.69701487,  2.38138211,  4.22719556,\n",
              "         6.69010937,  1.21101129,  3.71082669,  6.21213698,  0.91031593,\n",
              "         3.69137782,  5.33922058,  0.91679847,  3.74498463,  5.34844643,\n",
              "         1.65382707,  3.71182323,  4.86648512,  2.28813112,  3.97836095,\n",
              "         4.44037533,  2.29511261,  3.82651752,  5.05348611,  1.25439608,\n",
              "         6.84943324, 11.08984292,  1.44413829,  8.39854008, 11.64784998,\n",
              "         1.55010474,  6.90902358,  9.95313197,  1.83209991,  4.06089061,\n",
              "         5.90520763,  2.0043897 ,  4.26634121,  6.18047184,  2.25397253,\n",
              "         4.12920731,  7.8001405 ,  0.96167815,  3.97960871,  6.11888719,\n",
              "         0.90981704,  3.77515453,  5.0918833 ,  1.12025505,  3.99905437,\n",
              "         5.28262264,  1.76652515,  3.91727394,  4.72062534,  1.88146842,\n",
              "         3.96190476,  5.13127756,  2.29561138,  3.62031895,  4.77797329,\n",
              "         1.56880504,  9.62600833, 16.35700774,  1.67427248, 12.18790644,\n",
              "        17.44135684,  1.94629467,  9.90451211, 15.74115348,  1.75131619,\n",
              "         4.43389279,  6.25252879,  1.788966  ,  4.61241513,  5.69352424,\n",
              "         2.34647572,  4.36058855,  7.38824201,  1.04395747,  4.13992947,\n",
              "         5.63044292,  1.06839204,  4.14341986,  5.11157995,  1.03124219,\n",
              "         3.99057806,  5.91917014,  1.76178837,  3.80557323,  4.79617393,\n",
              "         2.12656295,  4.17059666,  4.30972463,  2.32652861,  3.75047177,\n",
              "         5.41177827,  1.66604578, 14.67749959, 23.75826663,  2.81148088,\n",
              "        19.5467267 , 24.24067444,  2.60952133, 14.88245159, 23.46549785,\n",
              "         1.8246215 ,  4.73334301,  7.04815173,  2.00738275,  4.27631372,\n",
              "         6.29965293,  2.13927943,  5.26666605,  7.13442153,  1.03398484,\n",
              "         3.87114751,  5.95108527,  0.93425161,  3.83649075,  5.78153878,\n",
              "         0.94547153,  3.81330204,  5.23475045,  1.91338271,  4.19553012,\n",
              "         4.90039486,  1.87149507,  3.91652614,  5.01159823,  1.88795125,\n",
              "         4.0768488 ,  5.21904361,  1.82038218, 18.91541731, 26.90928793,\n",
              "         2.51352817, 23.62207866, 31.22923505,  2.42775798, 21.14121366,\n",
              "        26.56321365,  1.74957204,  4.43140066,  6.72975177,  2.10187823,\n",
              "         4.26733816,  6.14431852,  2.23626971,  4.56504232,  7.4647879 ,\n",
              "         1.00680757,  3.90854788,  5.6960178 ,  0.92028868,  4.11524415,\n",
              "         6.19942057,  1.02426142,  3.70758486,  5.51550013,  1.75256306,\n",
              "         4.18879801,  4.61715198,  1.92934012,  3.93971401,  5.31603396,\n",
              "         2.05650097,  3.77640122,  4.98866022,  2.01386517, 17.87245667,\n",
              "        29.29141808,  2.46715319, 25.63918406, 29.98132265,  2.9962371 ,\n",
              "        20.82655483, 26.67890406,  1.92310768,  4.07385457,  7.53609574,\n",
              "         2.36941373,  4.76650226,  6.76790035,  2.17942184,  4.4862529 ,\n",
              "         6.97434884,  1.0379746 ,  4.52440059,  5.71845657,  0.89760023,\n",
              "         4.18555641,  5.6588667 ,  1.03199035,  3.99232334,  5.47410977,\n",
              "         1.74633002,  3.95567197,  4.58748168,  1.92909098,  4.16660726,\n",
              "         4.98566675,  2.05301023,  3.637025  ,  5.92939472,  2.03555673,\n",
              "        16.63775784, 27.90163493,  2.87780398, 25.49905956, 26.27049708,\n",
              "         3.35577685, 17.44409937, 25.06347358,  1.8682546 ,  4.38701755,\n",
              "         6.69534409,  1.877729  ,  4.26384646,  6.933707  ,  2.16994685,\n",
              "         4.35186189,  5.25793904]),\n",
              " 'std_fit_time': array([0.03980269, 0.25770405, 0.14756602, 0.06332543, 0.18868775,\n",
              "        0.11823382, 0.12694717, 0.38429818, 0.55472755, 0.05453049,\n",
              "        0.5282766 , 0.4091574 , 0.22558136, 0.40582038, 0.53757235,\n",
              "        0.22850919, 0.23592102, 0.52768729, 0.13008321, 1.1729539 ,\n",
              "        0.24296669, 0.32275883, 0.606805  , 0.80134456, 0.16837325,\n",
              "        0.60716952, 1.01689025, 0.08235497, 0.51318705, 0.61024028,\n",
              "        0.25811227, 0.04225646, 0.78453631, 0.19483455, 0.06099488,\n",
              "        1.12782269, 0.1934768 , 0.20834632, 0.6308381 , 0.03423323,\n",
              "        0.29200344, 0.56168276, 0.07227512, 0.39698918, 0.5369096 ,\n",
              "        0.0913068 , 0.19438302, 0.66834888, 0.45258232, 0.6127525 ,\n",
              "        0.20407847, 0.24208946, 0.43583735, 0.48499451, 0.11827182,\n",
              "        1.06629454, 1.39576033, 0.2190516 , 1.10974972, 1.45387815,\n",
              "        0.205221  , 0.18580432, 0.75093593, 0.07820294, 0.54474515,\n",
              "        0.80933272, 0.30730314, 0.52595575, 0.65398871, 0.25953769,\n",
              "        0.11671607, 0.69986249, 0.10785142, 0.56588735, 0.76466021,\n",
              "        0.01622473, 0.39595121, 0.1238555 , 0.03214366, 0.36075378,\n",
              "        0.45406456, 0.05998313, 0.49927173, 0.54951137, 0.06773228,\n",
              "        0.63965864, 0.74104438, 0.38994717, 0.04527189, 0.46439751,\n",
              "        0.18640499, 1.9683829 , 1.21590749, 0.22591823, 1.26924075,\n",
              "        1.18027577, 0.35222996, 0.19860073, 1.16785002, 0.10453399,\n",
              "        0.54767154, 0.57725131, 0.10147454, 0.34007411, 0.12569244,\n",
              "        0.39010635, 0.46996261, 0.58464939, 0.15361836, 0.42103714,\n",
              "        0.58088531, 0.11025219, 0.1682353 , 0.16180405, 0.08552427,\n",
              "        0.6074545 , 0.79052727, 0.05973389, 0.50449631, 0.60866382,\n",
              "        0.22083805, 0.54438224, 0.1306685 , 0.25214244, 0.2687259 ,\n",
              "        0.37865917, 0.21732494, 2.54155505, 0.68181276, 0.78586173,\n",
              "        2.13456472, 2.60905353, 0.26560263, 2.15252974, 0.73989257,\n",
              "        0.08072372, 0.39416408, 0.87431524, 0.27312083, 0.58089167,\n",
              "        0.57918946, 0.32023818, 0.60052109, 1.06182972, 0.10321313,\n",
              "        0.4741226 , 0.72893982, 0.02936145, 0.69798322, 0.74990815,\n",
              "        0.06220368, 0.4398648 , 0.34027144, 0.14891022, 0.64833841,\n",
              "        0.76770143, 0.09807747, 0.44617019, 0.57536507, 0.05715776,\n",
              "        0.60142437, 0.88406098, 0.28040698, 3.34924512, 0.4049707 ,\n",
              "        0.75442917, 1.5005801 , 4.66747678, 0.13113994, 3.59823961,\n",
              "        0.38507089, 0.0227251 , 0.58496569, 0.94226774, 0.37430166,\n",
              "        0.36008449, 0.88510135, 0.34120922, 0.45093785, 0.89141622,\n",
              "        0.12835868, 0.5294153 , 0.28516383, 0.04207352, 0.75714941,\n",
              "        0.92208822, 0.17872291, 0.590277  , 0.50907649, 0.03811057,\n",
              "        0.59353408, 0.55895223, 0.03932579, 0.46872719, 0.70255433,\n",
              "        0.25130501, 0.10238697, 0.73964042, 0.32940751, 3.01009552,\n",
              "        3.92036931, 0.30638832, 3.8866594 , 4.85292662, 0.07354448,\n",
              "        2.66169034, 2.96559611, 0.06031756, 0.18517973, 0.82557545,\n",
              "        0.41525351, 0.91456241, 1.1602182 , 0.33140241, 0.41380114,\n",
              "        1.05390998, 0.1427669 , 0.40719533, 0.72564035, 0.03981817,\n",
              "        0.73009136, 0.77303779, 0.15282068, 0.59826062, 0.51226513,\n",
              "        0.04844539, 0.3631543 , 0.49596231, 0.06611196, 0.55779395,\n",
              "        0.6115188 , 0.25314067, 0.08595994, 0.81179335, 0.32220558,\n",
              "        2.44895268, 3.95306809, 0.38748009, 3.58373115, 0.99231422,\n",
              "        0.37687302, 1.41258618, 1.4521787 , 0.13814246, 0.60372142,\n",
              "        0.13599297, 0.06385844, 0.16671755, 1.00729497, 0.2762203 ,\n",
              "        0.37804211, 0.10541393]),\n",
              " 'mean_score_time': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.35679561, 0.61086738,\n",
              "        0.64228183, 0.33934289, 0.65848887, 0.61161476, 0.30692929,\n",
              "        0.612611  , 0.61660033, 1.52940935, 2.07445192, 2.12232453,\n",
              "        1.73411292, 1.88022137, 2.01137191, 0.73727798, 1.17934644,\n",
              "        1.53115541, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.32213813,\n",
              "        0.61161458, 0.60164237, 0.32163996, 0.646272  , 0.58593327,\n",
              "        0.31166732, 0.58618242, 0.55127543, 1.54437035, 2.35071284,\n",
              "        1.94454956, 1.62839526, 2.1173377 , 1.82162869, 0.68142796,\n",
              "        1.19804657, 1.5775314 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.3353526 , 0.79188281, 0.65824062, 0.29820263, 0.62059104,\n",
              "        0.61435741, 0.33734828, 0.56947738, 0.60014528, 1.4827854 ,\n",
              "        2.17717725, 2.06148702, 1.55259782, 2.45219266, 1.71790606,\n",
              "        0.78091103, 1.17361164, 1.35961413, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.30368811, 0.77268302, 0.68436956, 0.40092862,\n",
              "        0.69439322, 0.68192691, 0.32438302, 0.75647634, 0.66522056,\n",
              "        1.52741551, 2.10661542, 2.03505689, 1.66554487, 2.11609137,\n",
              "        1.7550568 , 0.64552325, 1.29653263, 1.77575105, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.3193953 , 0.78664619, 0.60687739,\n",
              "        0.36277962, 0.70710963, 0.73303986, 0.30842537, 0.88214123,\n",
              "        0.57346666, 1.33592701, 2.05799603, 2.33475667, 1.7218948 ,\n",
              "        2.07719487, 1.93632197, 0.61909449, 1.248411  , 1.64310634,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.38422203, 0.67245185,\n",
              "        0.66297722, 0.37923634, 0.84823197, 0.67195278, 0.32313663,\n",
              "        0.75498104, 0.54479229, 1.59647906, 1.99865645, 2.23502266,\n",
              "        1.87947267, 2.16122049, 1.88047099, 0.67195278, 1.18732494,\n",
              "        1.47555441, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.41115028,\n",
              "        0.72655684, 0.72531009, 0.40391988, 0.85670918, 0.60538054,\n",
              "        0.36751628, 0.58294135, 0.61884546, 1.49824303, 2.03007174,\n",
              "        1.99990249, 1.46558064, 2.09190547, 1.79968739, 0.67295063,\n",
              "        0.93051147, 0.76869428]),\n",
              " 'std_score_time': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.0430669 , 0.09110993,\n",
              "        0.07139791, 0.06327917, 0.05930751, 0.11784026, 0.03261752,\n",
              "        0.11221796, 0.05444969, 0.04159217, 0.21197078, 0.27680888,\n",
              "        0.20794695, 0.06822946, 0.35510234, 0.05422113, 0.02200351,\n",
              "        0.22126511, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.06133012,\n",
              "        0.06264327, 0.04762931, 0.03793461, 0.03016038, 0.07541068,\n",
              "        0.01730947, 0.03133622, 0.0271612 , 0.05466491, 0.45240559,\n",
              "        0.23285367, 0.21833876, 0.23290757, 0.25077751, 0.07275178,\n",
              "        0.06045323, 0.19527304, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.03282432, 0.25857242, 0.07769651, 0.03069922, 0.04781656,\n",
              "        0.08985957, 0.05120274, 0.01982126, 0.06756635, 0.09548317,\n",
              "        0.29333008, 0.26489654, 0.05720722, 0.36474327, 0.06333816,\n",
              "        0.16209489, 0.06655809, 0.01714967, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00583623, 0.11980863, 0.11254019, 0.10823445,\n",
              "        0.10105691, 0.08480072, 0.03630597, 0.08606112, 0.12296524,\n",
              "        0.09972934, 0.24897473, 0.30469685, 0.27573107, 0.29299068,\n",
              "        0.05025063, 0.07729334, 0.17075485, 0.32150171, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.04064259, 0.10847834, 0.02391996,\n",
              "        0.06704231, 0.104148  , 0.08272088, 0.0150817 , 0.13867264,\n",
              "        0.04951663, 0.06779011, 0.34154118, 0.44209116, 0.32176713,\n",
              "        0.21391272, 0.20869302, 0.06475114, 0.12545255, 0.25921695,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.07689984, 0.04712396,\n",
              "        0.17418284, 0.0539595 , 0.15296969, 0.03511608, 0.01897729,\n",
              "        0.1295982 , 0.01049273, 0.04797256, 0.13641403, 0.463895  ,\n",
              "        0.23068037, 0.25291612, 0.19649795, 0.08142902, 0.0432693 ,\n",
              "        0.14884907, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.09102657,\n",
              "        0.10752366, 0.11029291, 0.07071566, 0.11484882, 0.01472634,\n",
              "        0.09151767, 0.02722713, 0.0904898 , 0.13225244, 0.04312998,\n",
              "        0.04549754, 0.08479207, 0.34043705, 0.11034909, 0.10779139,\n",
              "        0.11737882, 0.03107324]),\n",
              " 'param_clf__C': masked_array(data=[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
              "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
              "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
              "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
              "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
              "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
              "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
              "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
              "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 1.0, 1.0,\n",
              "                    1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
              "                    1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
              "                    1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
              "                    1.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0,\n",
              "                    10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0,\n",
              "                    10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0,\n",
              "                    10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0,\n",
              "                    10.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0,\n",
              "                    100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0,\n",
              "                    100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0,\n",
              "                    100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0,\n",
              "                    100.0, 100.0, 100.0, 100.0, 100.0, 1000.0, 1000.0,\n",
              "                    1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0,\n",
              "                    1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0,\n",
              "                    1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0,\n",
              "                    1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0,\n",
              "                    1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_clf__penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
              "                    'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
              "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
              "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
              "                    'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
              "                    'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
              "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
              "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
              "                    'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
              "                    'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
              "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
              "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
              "                    'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
              "                    'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
              "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
              "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
              "                    'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
              "                    'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
              "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
              "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
              "                    'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
              "                    'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
              "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
              "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
              "                    'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
              "                    'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
              "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
              "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_vect__analyzer': masked_array(data=['word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
              "                    'word', 'word', 'char', 'char', 'char', 'char', 'char',\n",
              "                    'char', 'char', 'char', 'char', 'word', 'word', 'word',\n",
              "                    'word', 'word', 'word', 'word', 'word', 'word', 'char',\n",
              "                    'char', 'char', 'char', 'char', 'char', 'char', 'char',\n",
              "                    'char', 'word', 'word', 'word', 'word', 'word', 'word',\n",
              "                    'word', 'word', 'word', 'char', 'char', 'char', 'char',\n",
              "                    'char', 'char', 'char', 'char', 'char', 'word', 'word',\n",
              "                    'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
              "                    'char', 'char', 'char', 'char', 'char', 'char', 'char',\n",
              "                    'char', 'char', 'word', 'word', 'word', 'word', 'word',\n",
              "                    'word', 'word', 'word', 'word', 'char', 'char', 'char',\n",
              "                    'char', 'char', 'char', 'char', 'char', 'char', 'word',\n",
              "                    'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
              "                    'word', 'char', 'char', 'char', 'char', 'char', 'char',\n",
              "                    'char', 'char', 'char', 'word', 'word', 'word', 'word',\n",
              "                    'word', 'word', 'word', 'word', 'word', 'char', 'char',\n",
              "                    'char', 'char', 'char', 'char', 'char', 'char', 'char',\n",
              "                    'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
              "                    'word', 'word', 'char', 'char', 'char', 'char', 'char',\n",
              "                    'char', 'char', 'char', 'char', 'word', 'word', 'word',\n",
              "                    'word', 'word', 'word', 'word', 'word', 'word', 'char',\n",
              "                    'char', 'char', 'char', 'char', 'char', 'char', 'char',\n",
              "                    'char', 'word', 'word', 'word', 'word', 'word', 'word',\n",
              "                    'word', 'word', 'word', 'char', 'char', 'char', 'char',\n",
              "                    'char', 'char', 'char', 'char', 'char', 'word', 'word',\n",
              "                    'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
              "                    'char', 'char', 'char', 'char', 'char', 'char', 'char',\n",
              "                    'char', 'char', 'word', 'word', 'word', 'word', 'word',\n",
              "                    'word', 'word', 'word', 'word', 'char', 'char', 'char',\n",
              "                    'char', 'char', 'char', 'char', 'char', 'char', 'word',\n",
              "                    'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
              "                    'word', 'char', 'char', 'char', 'char', 'char', 'char',\n",
              "                    'char', 'char', 'char', 'word', 'word', 'word', 'word',\n",
              "                    'word', 'word', 'word', 'word', 'word', 'char', 'char',\n",
              "                    'char', 'char', 'char', 'char', 'char', 'char', 'char'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_vect__max_df': masked_array(data=[0.5, 0.5, 0.5, 0.75, 0.75, 0.75, 1.0, 1.0, 1.0, 0.5,\n",
              "                    0.5, 0.5, 0.75, 0.75, 0.75, 1.0, 1.0, 1.0, 0.5, 0.5,\n",
              "                    0.5, 0.75, 0.75, 0.75, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5,\n",
              "                    0.75, 0.75, 0.75, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 0.75,\n",
              "                    0.75, 0.75, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 0.75, 0.75,\n",
              "                    0.75, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 0.75, 0.75, 0.75,\n",
              "                    1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 0.75, 0.75, 0.75, 1.0,\n",
              "                    1.0, 1.0, 0.5, 0.5, 0.5, 0.75, 0.75, 0.75, 1.0, 1.0,\n",
              "                    1.0, 0.5, 0.5, 0.5, 0.75, 0.75, 0.75, 1.0, 1.0, 1.0,\n",
              "                    0.5, 0.5, 0.5, 0.75, 0.75, 0.75, 1.0, 1.0, 1.0, 0.5,\n",
              "                    0.5, 0.5, 0.75, 0.75, 0.75, 1.0, 1.0, 1.0, 0.5, 0.5,\n",
              "                    0.5, 0.75, 0.75, 0.75, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5,\n",
              "                    0.75, 0.75, 0.75, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 0.75,\n",
              "                    0.75, 0.75, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 0.75, 0.75,\n",
              "                    0.75, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 0.75, 0.75, 0.75,\n",
              "                    1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 0.75, 0.75, 0.75, 1.0,\n",
              "                    1.0, 1.0, 0.5, 0.5, 0.5, 0.75, 0.75, 0.75, 1.0, 1.0,\n",
              "                    1.0, 0.5, 0.5, 0.5, 0.75, 0.75, 0.75, 1.0, 1.0, 1.0,\n",
              "                    0.5, 0.5, 0.5, 0.75, 0.75, 0.75, 1.0, 1.0, 1.0, 0.5,\n",
              "                    0.5, 0.5, 0.75, 0.75, 0.75, 1.0, 1.0, 1.0, 0.5, 0.5,\n",
              "                    0.5, 0.75, 0.75, 0.75, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5,\n",
              "                    0.75, 0.75, 0.75, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 0.75,\n",
              "                    0.75, 0.75, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 0.75, 0.75,\n",
              "                    0.75, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 0.75, 0.75, 0.75,\n",
              "                    1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 0.75, 0.75, 0.75, 1.0,\n",
              "                    1.0, 1.0],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_vect__ngram_range': masked_array(data=[(1, 1), (2, 2), (3, 3), (1, 1), (2, 2), (3, 3), (1, 1),\n",
              "                    (2, 2), (3, 3), (1, 1), (2, 2), (3, 3), (1, 1), (2, 2),\n",
              "                    (3, 3), (1, 1), (2, 2), (3, 3), (1, 1), (2, 2), (3, 3),\n",
              "                    (1, 1), (2, 2), (3, 3), (1, 1), (2, 2), (3, 3), (1, 1),\n",
              "                    (2, 2), (3, 3), (1, 1), (2, 2), (3, 3), (1, 1), (2, 2),\n",
              "                    (3, 3), (1, 1), (2, 2), (3, 3), (1, 1), (2, 2), (3, 3),\n",
              "                    (1, 1), (2, 2), (3, 3), (1, 1), (2, 2), (3, 3), (1, 1),\n",
              "                    (2, 2), (3, 3), (1, 1), (2, 2), (3, 3), (1, 1), (2, 2),\n",
              "                    (3, 3), (1, 1), (2, 2), (3, 3), (1, 1), (2, 2), (3, 3),\n",
              "                    (1, 1), (2, 2), (3, 3), (1, 1), (2, 2), (3, 3), (1, 1),\n",
              "                    (2, 2), (3, 3), (1, 1), (2, 2), (3, 3), (1, 1), (2, 2),\n",
              "                    (3, 3), (1, 1), (2, 2), (3, 3), (1, 1), (2, 2), (3, 3),\n",
              "                    (1, 1), (2, 2), (3, 3), (1, 1), (2, 2), (3, 3), (1, 1),\n",
              "                    (2, 2), (3, 3), (1, 1), (2, 2), (3, 3), (1, 1), (2, 2),\n",
              "                    (3, 3), (1, 1), (2, 2), (3, 3), (1, 1), (2, 2), (3, 3),\n",
              "                    (1, 1), (2, 2), (3, 3), (1, 1), (2, 2), (3, 3), (1, 1),\n",
              "                    (2, 2), (3, 3), (1, 1), (2, 2), (3, 3), (1, 1), (2, 2),\n",
              "                    (3, 3), (1, 1), (2, 2), (3, 3), (1, 1), (2, 2), (3, 3),\n",
              "                    (1, 1), (2, 2), (3, 3), (1, 1), (2, 2), (3, 3), (1, 1),\n",
              "                    (2, 2), (3, 3), (1, 1), (2, 2), (3, 3), (1, 1), (2, 2),\n",
              "                    (3, 3), (1, 1), (2, 2), (3, 3), (1, 1), (2, 2), (3, 3),\n",
              "                    (1, 1), (2, 2), (3, 3), (1, 1), (2, 2), (3, 3), (1, 1),\n",
              "                    (2, 2), (3, 3), (1, 1), (2, 2), (3, 3), (1, 1), (2, 2),\n",
              "                    (3, 3), (1, 1), (2, 2), (3, 3), (1, 1), (2, 2), (3, 3),\n",
              "                    (1, 1), (2, 2), (3, 3), (1, 1), (2, 2), (3, 3), (1, 1),\n",
              "                    (2, 2), (3, 3), (1, 1), (2, 2), (3, 3), (1, 1), (2, 2),\n",
              "                    (3, 3), (1, 1), (2, 2), (3, 3), (1, 1), (2, 2), (3, 3),\n",
              "                    (1, 1), (2, 2), (3, 3), (1, 1), (2, 2), (3, 3), (1, 1),\n",
              "                    (2, 2), (3, 3), (1, 1), (2, 2), (3, 3), (1, 1), (2, 2),\n",
              "                    (3, 3), (1, 1), (2, 2), (3, 3), (1, 1), (2, 2), (3, 3),\n",
              "                    (1, 1), (2, 2), (3, 3), (1, 1), (2, 2), (3, 3), (1, 1),\n",
              "                    (2, 2), (3, 3), (1, 1), (2, 2), (3, 3), (1, 1), (2, 2),\n",
              "                    (3, 3), (1, 1), (2, 2), (3, 3), (1, 1), (2, 2), (3, 3),\n",
              "                    (1, 1), (2, 2), (3, 3), (1, 1), (2, 2), (3, 3), (1, 1),\n",
              "                    (2, 2), (3, 3), (1, 1), (2, 2), (3, 3), (1, 1), (2, 2),\n",
              "                    (3, 3), (1, 1), (2, 2), (3, 3), (1, 1), (2, 2), (3, 3)],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'clf__C': 0.001,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 0.001,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 0.001,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 0.001,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 0.001,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 0.001,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 0.001,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 0.001,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 0.001,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 0.001,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 0.001,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 0.001,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 0.001,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 0.001,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 0.001,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 0.001,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 0.001,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 0.001,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 0.001,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 0.001,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 0.001,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 0.001,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 0.001,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 0.001,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 0.001,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 0.001,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 0.001,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 0.001,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 0.001,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 0.001,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 0.001,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 0.001,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 0.001,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 0.001,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 0.001,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 0.001,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 0.01,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 0.01,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 0.01,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 0.01,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 0.01,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 0.01,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 0.01,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 0.01,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 0.01,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 0.01,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 0.01,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 0.01,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 0.01,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 0.01,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 0.01,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 0.01,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 0.01,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 0.01,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 0.01,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 0.01,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 0.01,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 0.01,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 0.01,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 0.01,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 0.01,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 0.01,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 0.01,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 0.01,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 0.01,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 0.01,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 0.01,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 0.01,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 0.01,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 0.01,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 0.01,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 0.01,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 0.1,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 0.1,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 0.1,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 0.1,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 0.1,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 0.1,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 0.1,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 0.1,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 0.1,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 0.1,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 0.1,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 0.1,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 0.1,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 0.1,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 0.1,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 0.1,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 0.1,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 0.1,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 0.1,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 0.1,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 0.1,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 0.1,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 0.1,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 0.1,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 0.1,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 0.1,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 0.1,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 0.1,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 0.1,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 0.1,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 0.1,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 0.1,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 0.1,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 0.1,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 0.1,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 0.1,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 1.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 1.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 1.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 1.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 1.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 1.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 1.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 1.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 1.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 1.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 1.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 1.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 1.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 1.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 1.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 1.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 1.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 1.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 1.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 1.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 1.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 1.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 1.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 1.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 1.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 1.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 1.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 1.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 1.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 1.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 1.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 1.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 1.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 1.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 1.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 1.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 10.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 10.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 10.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 10.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 10.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 10.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 10.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 10.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 10.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 10.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 10.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 10.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 10.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 10.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 10.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 10.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 10.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 10.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 10.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 10.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 10.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 10.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 10.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 10.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 10.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 10.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 10.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 10.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 10.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 10.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 10.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 10.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 10.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 10.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 10.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 10.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 100.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 100.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 100.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 100.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 100.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 100.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 100.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 100.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 100.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 100.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 100.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 100.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 100.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 100.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 100.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 100.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 100.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 100.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 100.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 100.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 100.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 100.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 100.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 100.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 100.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 100.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 100.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 100.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 100.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 100.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 100.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 100.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 100.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 100.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 100.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 100.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 1000.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 1000.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 1000.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 1000.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 1000.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 1000.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 1000.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 1000.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 1000.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 1000.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 1000.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 1000.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 1000.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 1000.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 1000.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 1000.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 1000.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 1000.0,\n",
              "   'clf__penalty': 'l1',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 1000.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 1000.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 1000.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 1000.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 1000.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 1000.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 1000.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 1000.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 1000.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'word',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 1000.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 1000.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 1000.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.5,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 1000.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 1000.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 1000.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 0.75,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__C': 1000.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__C': 1000.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__C': 1000.0,\n",
              "   'clf__penalty': 'l2',\n",
              "   'vect__analyzer': 'char',\n",
              "   'vect__max_df': 1.0,\n",
              "   'vect__ngram_range': (3, 3)}],\n",
              " 'split0_test_accuracy': array([       nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.90971429, 0.83257143,\n",
              "        0.64171429, 0.912     , 0.83257143, 0.64171429, 0.90742857,\n",
              "        0.83257143, 0.64171429, 0.508     , 0.85314286, 0.92285714,\n",
              "        0.53428571, 0.87028571, 0.91942857, 0.70742857, 0.88057143,\n",
              "        0.91657143,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.93314286,\n",
              "        0.90057143, 0.80342857, 0.93028571, 0.90057143, 0.80342857,\n",
              "        0.92914286, 0.90057143, 0.80342857, 0.508     , 0.86457143,\n",
              "        0.92285714, 0.53771429, 0.88342857, 0.92514286, 0.70342857,\n",
              "        0.89085714, 0.92228571,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.93542857, 0.91142857, 0.84      , 0.93371429, 0.91142857,\n",
              "        0.84      , 0.93314286, 0.91142857, 0.84      , 0.508     ,\n",
              "        0.86571429, 0.91657143, 0.53485714, 0.88228571, 0.91942857,\n",
              "        0.69942857, 0.88457143, 0.91257143,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.93142857, 0.91314286, 0.836     , 0.928     ,\n",
              "        0.91314286, 0.836     , 0.92914286, 0.91314286, 0.836     ,\n",
              "        0.508     , 0.86171429, 0.91142857, 0.53371429, 0.868     ,\n",
              "        0.90914286, 0.70114286, 0.88571429, 0.90571429,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.92742857, 0.912     , 0.83028571,\n",
              "        0.92285714, 0.912     , 0.83028571, 0.92228571, 0.912     ,\n",
              "        0.83028571, 0.508     , 0.85542857, 0.908     , 0.53371429,\n",
              "        0.86171429, 0.90342857, 0.70114286, 0.88685714, 0.90342857,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.92457143, 0.91142857,\n",
              "        0.82685714, 0.92457143, 0.91142857, 0.82685714, 0.92342857,\n",
              "        0.91142857, 0.82685714, 0.508     , 0.85714286, 0.904     ,\n",
              "        0.53371429, 0.86342857, 0.90342857, 0.70285714, 0.88057143,\n",
              "        0.90628571,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.92228571,\n",
              "        0.91142857, 0.82285714, 0.92285714, 0.91142857, 0.82285714,\n",
              "        0.92228571, 0.91142857, 0.82285714, 0.508     , 0.85714286,\n",
              "        0.90171429, 0.53371429, 0.86228571, 0.90228571, 0.70228571,\n",
              "        0.88285714, 0.90628571]),\n",
              " 'split1_test_accuracy': array([       nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.908     , 0.80857143,\n",
              "        0.64228571, 0.91485714, 0.80857143, 0.64228571, 0.91428571,\n",
              "        0.80857143, 0.64228571, 0.51314286, 0.87542857, 0.93085714,\n",
              "        0.54      , 0.87942857, 0.93828571, 0.72742857, 0.896     ,\n",
              "        0.93142857,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.94457143,\n",
              "        0.88342857, 0.78914286, 0.94571429, 0.88342857, 0.78914286,\n",
              "        0.94171429, 0.88342857, 0.78914286, 0.51314286, 0.88971429,\n",
              "        0.93942857, 0.53714286, 0.9       , 0.94171429, 0.72857143,\n",
              "        0.90685714, 0.93771429,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.948     , 0.91371429, 0.83942857, 0.94742857, 0.91371429,\n",
              "        0.83942857, 0.94571429, 0.91371429, 0.83942857, 0.51314286,\n",
              "        0.89314286, 0.93314286, 0.53828571, 0.89771429, 0.92914286,\n",
              "        0.72857143, 0.90685714, 0.93142857,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.94342857, 0.91371429, 0.84342857, 0.94285714,\n",
              "        0.91371429, 0.84342857, 0.94228571, 0.91371429, 0.84342857,\n",
              "        0.51314286, 0.88571429, 0.92057143, 0.53828571, 0.88457143,\n",
              "        0.92628571, 0.728     , 0.90114286, 0.92457143,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.93771429, 0.91714286, 0.844     ,\n",
              "        0.93942857, 0.91714286, 0.844     , 0.93828571, 0.91714286,\n",
              "        0.844     , 0.51314286, 0.87371429, 0.91885714, 0.53828571,\n",
              "        0.88171429, 0.92171429, 0.73028571, 0.9       , 0.91828571,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.93657143, 0.91657143,\n",
              "        0.84057143, 0.93485714, 0.91657143, 0.84057143, 0.93657143,\n",
              "        0.91657143, 0.84057143, 0.51314286, 0.87314286, 0.91657143,\n",
              "        0.53828571, 0.87542857, 0.92285714, 0.72742857, 0.90685714,\n",
              "        0.91542857,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.93542857,\n",
              "        0.91657143, 0.84114286, 0.936     , 0.91657143, 0.84114286,\n",
              "        0.93485714, 0.91657143, 0.84114286, 0.51314286, 0.86857143,\n",
              "        0.91542857, 0.53828571, 0.87657143, 0.92114286, 0.728     ,\n",
              "        0.90342857, 0.916     ]),\n",
              " 'split2_test_accuracy': array([       nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.89771429, 0.804     ,\n",
              "        0.632     , 0.89885714, 0.804     , 0.632     , 0.89828571,\n",
              "        0.804     , 0.632     , 0.50342857, 0.85371429, 0.92228571,\n",
              "        0.53142857, 0.87028571, 0.924     , 0.72114286, 0.88857143,\n",
              "        0.92342857,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.93085714,\n",
              "        0.88171429, 0.77371429, 0.928     , 0.88171429, 0.77371429,\n",
              "        0.92457143, 0.88171429, 0.77371429, 0.50342857, 0.86057143,\n",
              "        0.92971429, 0.516     , 0.88285714, 0.92628571, 0.72171429,\n",
              "        0.89828571, 0.92685714,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.93371429, 0.90571429, 0.832     , 0.932     , 0.90571429,\n",
              "        0.832     , 0.93085714, 0.90571429, 0.832     , 0.50342857,\n",
              "        0.85485714, 0.92114286, 0.51771429, 0.88057143, 0.91714286,\n",
              "        0.72457143, 0.88857143, 0.91828571,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.93485714, 0.91085714, 0.83314286, 0.93257143,\n",
              "        0.91085714, 0.83314286, 0.93314286, 0.91085714, 0.83314286,\n",
              "        0.50342857, 0.85028571, 0.91142857, 0.51771429, 0.87485714,\n",
              "        0.90628571, 0.72342857, 0.88685714, 0.90342857,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.93314286, 0.91142857, 0.83542857,\n",
              "        0.93085714, 0.91142857, 0.83542857, 0.93085714, 0.91142857,\n",
              "        0.83542857, 0.50342857, 0.84685714, 0.908     , 0.51771429,\n",
              "        0.86971429, 0.90285714, 0.72514286, 0.88571429, 0.90285714,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.92857143, 0.91142857,\n",
              "        0.83371429, 0.928     , 0.91142857, 0.83371429, 0.92857143,\n",
              "        0.91142857, 0.83371429, 0.50342857, 0.84685714, 0.904     ,\n",
              "        0.51771429, 0.87314286, 0.90114286, 0.72514286, 0.88857143,\n",
              "        0.90171429,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.92628571,\n",
              "        0.90971429, 0.83142857, 0.928     , 0.90971429, 0.83142857,\n",
              "        0.92857143, 0.90971429, 0.83142857, 0.50342857, 0.844     ,\n",
              "        0.90285714, 0.51771429, 0.87257143, 0.90285714, 0.72514286,\n",
              "        0.88628571, 0.904     ]),\n",
              " 'split3_test_accuracy': array([       nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.91428571, 0.80342857,\n",
              "        0.64      , 0.91257143, 0.80342857, 0.64      , 0.912     ,\n",
              "        0.80342857, 0.64      , 0.52571429, 0.86285714, 0.93714286,\n",
              "        0.53371429, 0.88285714, 0.928     , 0.73028571, 0.89542857,\n",
              "        0.92685714,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.94285714,\n",
              "        0.88114286, 0.78914286, 0.94      , 0.88114286, 0.78914286,\n",
              "        0.936     , 0.88114286, 0.78914286, 0.52571429, 0.87942857,\n",
              "        0.93657143, 0.53657143, 0.89657143, 0.92914286, 0.73028571,\n",
              "        0.90228571, 0.93028571,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.94514286, 0.90742857, 0.83485714, 0.94742857, 0.90742857,\n",
              "        0.83485714, 0.94742857, 0.90742857, 0.83485714, 0.52571429,\n",
              "        0.88742857, 0.92342857, 0.53885714, 0.89428571, 0.92057143,\n",
              "        0.73085714, 0.89771429, 0.92      ,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.94228571, 0.91542857, 0.82      , 0.944     ,\n",
              "        0.91542857, 0.82      , 0.94571429, 0.91542857, 0.82      ,\n",
              "        0.52571429, 0.87714286, 0.91714286, 0.54      , 0.88171429,\n",
              "        0.91028571, 0.73085714, 0.89942857, 0.91371429,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.94057143, 0.916     , 0.824     ,\n",
              "        0.94057143, 0.916     , 0.824     , 0.94      , 0.916     ,\n",
              "        0.824     , 0.52571429, 0.87142857, 0.91371429, 0.54      ,\n",
              "        0.876     , 0.908     , 0.72971429, 0.89428571, 0.91485714,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.93942857, 0.91314286,\n",
              "        0.82285714, 0.93942857, 0.91314286, 0.82285714, 0.93942857,\n",
              "        0.91314286, 0.82285714, 0.52571429, 0.868     , 0.912     ,\n",
              "        0.54      , 0.87542857, 0.90857143, 0.72971429, 0.89542857,\n",
              "        0.91371429,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.93885714,\n",
              "        0.91371429, 0.82228571, 0.93771429, 0.91371429, 0.82228571,\n",
              "        0.94      , 0.91371429, 0.82228571, 0.52571429, 0.87142857,\n",
              "        0.90857143, 0.54      , 0.87485714, 0.90514286, 0.72914286,\n",
              "        0.89657143, 0.916     ]),\n",
              " 'mean_test_accuracy': array([       nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.90742857, 0.81214286,\n",
              "        0.639     , 0.90957143, 0.81214286, 0.639     , 0.908     ,\n",
              "        0.81214286, 0.639     , 0.51257143, 0.86128571, 0.92828571,\n",
              "        0.53485714, 0.87571429, 0.92742857, 0.72157143, 0.89014286,\n",
              "        0.92457143,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.93785714,\n",
              "        0.88671429, 0.78885714, 0.936     , 0.88671429, 0.78885714,\n",
              "        0.93285714, 0.88671429, 0.78885714, 0.51257143, 0.87357143,\n",
              "        0.93214286, 0.53185714, 0.89071429, 0.93057143, 0.721     ,\n",
              "        0.89957143, 0.92928571,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.94057143, 0.90957143, 0.83657143, 0.94014286, 0.90957143,\n",
              "        0.83657143, 0.93928571, 0.90957143, 0.83657143, 0.51257143,\n",
              "        0.87528571, 0.92357143, 0.53242857, 0.88871429, 0.92157143,\n",
              "        0.72085714, 0.89442857, 0.92057143,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.938     , 0.91328571, 0.83314286, 0.93685714,\n",
              "        0.91328571, 0.83314286, 0.93757143, 0.91328571, 0.83314286,\n",
              "        0.51257143, 0.86871429, 0.91514286, 0.53242857, 0.87728571,\n",
              "        0.913     , 0.72085714, 0.89328571, 0.91185714,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.93471429, 0.91414286, 0.83342857,\n",
              "        0.93342857, 0.91414286, 0.83342857, 0.93285714, 0.91414286,\n",
              "        0.83342857, 0.51257143, 0.86185714, 0.91214286, 0.53242857,\n",
              "        0.87228571, 0.909     , 0.72157143, 0.89171429, 0.90985714,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.93228571, 0.91314286,\n",
              "        0.831     , 0.93171429, 0.91314286, 0.831     , 0.932     ,\n",
              "        0.91314286, 0.831     , 0.51257143, 0.86128571, 0.90914286,\n",
              "        0.53242857, 0.87185714, 0.909     , 0.72128571, 0.89285714,\n",
              "        0.90928571,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.93071429,\n",
              "        0.91285714, 0.82942857, 0.93114286, 0.91285714, 0.82942857,\n",
              "        0.93142857, 0.91285714, 0.82942857, 0.51257143, 0.86028571,\n",
              "        0.90714286, 0.53242857, 0.87157143, 0.90785714, 0.72114286,\n",
              "        0.89228571, 0.91057143]),\n",
              " 'std_test_accuracy': array([       nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.00606092, 0.01196167,\n",
              "        0.00412805, 0.00627759, 0.01196167, 0.00412805, 0.00612789,\n",
              "        0.01196167, 0.00412805, 0.00832993, 0.00902943, 0.00613455,\n",
              "        0.00315582, 0.00556226, 0.00696346, 0.00880978, 0.00625153,\n",
              "        0.00542105,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.00594361,\n",
              "        0.00804452, 0.01050947, 0.0071941 , 0.00804452, 0.01050947,\n",
              "        0.00653406, 0.00804452, 0.01050947, 0.00832993, 0.01167152,\n",
              "        0.00641904, 0.00916404, 0.00767051, 0.00659623, 0.01063974,\n",
              "        0.00587454, 0.00563336,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.00611455, 0.0031655 , 0.00330738, 0.00731088, 0.0031655 ,\n",
              "        0.00330738, 0.00735541, 0.0031655 , 0.00330738, 0.00832993,\n",
              "        0.01561462, 0.00605249, 0.00863193, 0.00741069, 0.00454232,\n",
              "        0.01257467, 0.00861299, 0.00684523,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.0050224 , 0.00163507, 0.00846602, 0.00677932,\n",
              "        0.00163507, 0.00846602, 0.00669298, 0.00163507, 0.00846602,\n",
              "        0.00832993, 0.01368076, 0.00390708, 0.00880051, 0.00641904,\n",
              "        0.00780764, 0.01168638, 0.0070378 , 0.00827462,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.00497135, 0.00247023, 0.00732343,\n",
              "        0.00716568, 0.00247023, 0.00732343, 0.00700437, 0.00247023,\n",
              "        0.00732343, 0.00832993, 0.0111639 , 0.00452431, 0.00880051,\n",
              "        0.00743406, 0.00760639, 0.01196167, 0.0058064 , 0.00682582,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.00597273, 0.00209956,\n",
              "        0.00675368, 0.00579232, 0.00209956, 0.00675368, 0.00635032,\n",
              "        0.00209956, 0.00675368, 0.00832993, 0.01013682, 0.00539085,\n",
              "        0.00880051, 0.0049549 , 0.00844067, 0.0107618 , 0.00964259,\n",
              "        0.00556043,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.00669298,\n",
              "        0.00257143, 0.00767184, 0.00602715, 0.00257143, 0.00767184,\n",
              "        0.00665168, 0.00257143, 0.00767184, 0.00832993, 0.01081571,\n",
              "        0.00544359, 0.00880051, 0.00554573, 0.00774465, 0.01098422,\n",
              "        0.00817662, 0.00548839]),\n",
              " 'rank_test_accuracy': array([127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,\n",
              "        127, 127, 127, 127, 127,  56,  97, 110,  46,  97, 110,  54,  97,\n",
              "        110, 120,  79,  22, 113,  71,  23, 103,  65,  24, 127, 127, 127,\n",
              "        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,\n",
              "        127, 127,   5,  67, 100,   8,  67, 100,  11,  67, 100, 120,  73,\n",
              "         14, 119,  64,  20, 107,  58,  21, 127, 127, 127, 127, 127, 127,\n",
              "        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,   1,\n",
              "         47,  82,   2,  47,  82,   3,  47,  82, 120,  72,  25, 118,  66,\n",
              "         26, 108,  59,  27, 127, 127, 127, 127, 127, 127, 127, 127, 127,\n",
              "        127, 127, 127, 127, 127, 127, 127, 127, 127,   4,  32,  88,   7,\n",
              "         32,  88,   6,  32,  88, 120,  77,  28, 114,  70,  38, 108,  60,\n",
              "         43, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,\n",
              "        127, 127, 127, 127, 127, 127,   9,  29,  85,  10,  29,  85,  11,\n",
              "         29,  85, 120,  78,  42, 114,  74,  53, 104,  63,  45, 127, 127,\n",
              "        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,\n",
              "        127, 127, 127,  13,  35,  91,  16,  35,  91,  15,  35,  91, 120,\n",
              "         80,  51, 114,  75,  52, 105,  61,  50, 127, 127, 127, 127, 127,\n",
              "        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,\n",
              "         19,  39,  94,  18,  39,  94,  17,  39,  94, 120,  81,  57, 114,\n",
              "         76,  55, 106,  62,  44]),\n",
              " 'split0_test_f1': array([       nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.91002278, 0.81880025,\n",
              "        0.45620121, 0.91210046, 0.81880025, 0.45620121, 0.90689655,\n",
              "        0.81880025, 0.45620121, 0.39748076, 0.85372795, 0.92359932,\n",
              "        0.4620462 , 0.8713881 , 0.92002269, 0.70742857, 0.8821207 ,\n",
              "        0.91704545,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.93371105,\n",
              "        0.90057143, 0.78033206, 0.9307605 , 0.90057143, 0.78033206,\n",
              "        0.9294653 , 0.90057143, 0.78033206, 0.39748076, 0.86647887,\n",
              "        0.92307692, 0.47569669, 0.88526434, 0.92492837, 0.70291929,\n",
              "        0.8917847 , 0.92183908,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.93561254, 0.91306786, 0.84322508, 0.93394077, 0.91306786,\n",
              "        0.84322508, 0.93325727, 0.91306786, 0.84322508, 0.39748076,\n",
              "        0.86775464, 0.91589862, 0.4775353 , 0.88295455, 0.9186382 ,\n",
              "        0.6983945 , 0.88522727, 0.91161179,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.93158495, 0.91498881, 0.84427564, 0.9281642 ,\n",
              "        0.91498881, 0.84427564, 0.9294653 , 0.91498881, 0.84427564,\n",
              "        0.39748076, 0.86296716, 0.91045638, 0.47759283, 0.86792453,\n",
              "        0.90803933, 0.70028653, 0.88636364, 0.90467938,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.92747002, 0.9140625 , 0.84023669,\n",
              "        0.92281304, 0.9140625 , 0.84023669, 0.9221968 , 0.9140625 ,\n",
              "        0.84023669, 0.39748076, 0.85665722, 0.90720461, 0.47759283,\n",
              "        0.86139748, 0.90225564, 0.70028653, 0.88788222, 0.90236857,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.92439863, 0.91364903,\n",
              "        0.83770755, 0.92448513, 0.91364903, 0.83770755, 0.92325315,\n",
              "        0.91364903, 0.83770755, 0.39748076, 0.85795455, 0.90300231,\n",
              "        0.47759283, 0.86256469, 0.90225564, 0.70353478, 0.88185415,\n",
              "        0.90487239,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.92210767,\n",
              "        0.91384102, 0.83440171, 0.9226361 , 0.91384102, 0.83440171,\n",
              "        0.92201835, 0.91384102, 0.83440171, 0.39748076, 0.85811578,\n",
              "        0.90080738, 0.47759283, 0.86189112, 0.90086957, 0.70143266,\n",
              "        0.88398415, 0.90509259]),\n",
              " 'split1_test_f1': array([       nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.90815744, 0.78511867,\n",
              "        0.4527972 , 0.91480846, 0.78511867, 0.4527972 , 0.91418764,\n",
              "        0.78511867, 0.4527972 , 0.37991266, 0.87266355, 0.93144476,\n",
              "        0.42541042, 0.87810514, 0.93891403, 0.72121566, 0.8956422 ,\n",
              "        0.93235626,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.9451047 ,\n",
              "        0.88098016, 0.7554672 , 0.94623656, 0.88098016, 0.7554672 ,\n",
              "        0.94224236, 0.88098016, 0.7554672 , 0.37991266, 0.88824551,\n",
              "        0.93984109, 0.43277311, 0.89890237, 0.94204545, 0.72238457,\n",
              "        0.90561668, 0.93803297,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.94844193, 0.91386195, 0.83421829, 0.94790487, 0.91386195,\n",
              "        0.83421829, 0.94623656, 0.91386195, 0.83421829, 0.37991266,\n",
              "        0.8915942 , 0.93348493, 0.43575419, 0.89562682, 0.9294653 ,\n",
              "        0.72173404, 0.90506698, 0.93174061,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.94371802, 0.91425327, 0.84502262, 0.94318182,\n",
              "        0.91425327, 0.84502262, 0.94258101, 0.91425327, 0.84502262,\n",
              "        0.37991266, 0.88385598, 0.92061679, 0.43575419, 0.88228438,\n",
              "        0.92641187, 0.72196262, 0.89900759, 0.92422503,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.93782088, 0.91784703, 0.84841755,\n",
              "        0.9395667 , 0.91784703, 0.84841755, 0.93835616, 0.91784703,\n",
              "        0.84841755, 0.37991266, 0.87083577, 0.9184845 , 0.43575419,\n",
              "        0.87915937, 0.92175899, 0.7236534 , 0.89819663, 0.9178633 ,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.93660765, 0.91742081,\n",
              "        0.84611142, 0.93493151, 0.91742081, 0.84611142, 0.93660765,\n",
              "        0.91742081, 0.84611142, 0.37991266, 0.8703271 , 0.91609195,\n",
              "        0.43575419, 0.87191539, 0.92272467, 0.72121566, 0.90561668,\n",
              "        0.91484465,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.93539165,\n",
              "        0.91742081, 0.8469163 , 0.93607306, 0.91742081, 0.8469163 ,\n",
              "        0.93478261, 0.91742081, 0.8469163 , 0.37991266, 0.86549708,\n",
              "        0.91504018, 0.43575419, 0.87338804, 0.92087156, 0.72131148,\n",
              "        0.90168703, 0.91537133]),\n",
              " 'split2_test_f1': array([       nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.89858357, 0.78138942,\n",
              "        0.43109541, 0.89937464, 0.78138942, 0.43109541, 0.89897843,\n",
              "        0.78138942, 0.43109541, 0.37795276, 0.85253456, 0.92290249,\n",
              "        0.42253521, 0.8709494 , 0.92532285, 0.71528588, 0.88863507,\n",
              "        0.92429379,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.93144476,\n",
              "        0.88041594, 0.73279352, 0.92857143, 0.88041594, 0.73279352,\n",
              "        0.92525481, 0.88041594, 0.73279352, 0.37795276, 0.86073059,\n",
              "        0.92975443, 0.44676682, 0.88398415, 0.92649573, 0.71570344,\n",
              "        0.89886364, 0.92685714,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.93356243, 0.90662139, 0.82726204, 0.93180516, 0.90662139,\n",
              "        0.82726204, 0.93073841, 0.90662139, 0.82726204, 0.37795276,\n",
              "        0.85419059, 0.92087156, 0.44836601, 0.88036634, 0.91633006,\n",
              "        0.71911422, 0.88888889, 0.91767415,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.93418014, 0.91216216, 0.83465459, 0.93187067,\n",
              "        0.91216216, 0.83465459, 0.93240901, 0.91216216, 0.83465459,\n",
              "        0.37795276, 0.84925201, 0.91107286, 0.44836601, 0.87478559,\n",
              "        0.90509259, 0.7176196 , 0.88672769, 0.90168703,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.93217391, 0.91297024, 0.8387458 ,\n",
              "        0.93001735, 0.91297024, 0.8387458 , 0.93001735, 0.91297024,\n",
              "        0.8387458 , 0.37795276, 0.84562212, 0.90763052, 0.44836601,\n",
              "        0.86881473, 0.90150637, 0.71953353, 0.88597491, 0.9009324 ,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.92753623, 0.91306786,\n",
              "        0.83824347, 0.92699884, 0.91306786, 0.83824347, 0.92745212,\n",
              "        0.91306786, 0.83824347, 0.37795276, 0.84615385, 0.90344828,\n",
              "        0.44836601, 0.87270642, 0.89947705, 0.71920607, 0.88863507,\n",
              "        0.89964994,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.92513059,\n",
              "        0.91143498, 0.8363838 , 0.92682927, 0.91143498, 0.8363838 ,\n",
              "        0.92753623, 0.91143498, 0.8363838 , 0.37795276, 0.84301323,\n",
              "        0.90196078, 0.44836601, 0.87191269, 0.9009324 , 0.71953353,\n",
              "        0.88673876, 0.9020979 ]),\n",
              " 'split3_test_f1': array([       nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.91418764, 0.77948718,\n",
              "        0.45217391, 0.91262136, 0.77948718, 0.45217391, 0.91210046,\n",
              "        0.77948718, 0.45217391, 0.41134752, 0.86206897, 0.93735763,\n",
              "        0.45816733, 0.88292404, 0.92808219, 0.72202591, 0.895249  ,\n",
              "        0.92685714,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.94331066,\n",
              "        0.87892899, 0.76208897, 0.94050992, 0.87892899, 0.76208897,\n",
              "        0.93643587, 0.87892899, 0.76208897, 0.41134752, 0.88018171,\n",
              "        0.93653516, 0.47166124, 0.8966305 , 0.92881745, 0.72136954,\n",
              "        0.90178059, 0.93028571,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.94508009, 0.90784983, 0.8357021 , 0.94748858, 0.90784983,\n",
              "        0.8357021 , 0.94754846, 0.90784983, 0.8357021 , 0.41134752,\n",
              "        0.88863765, 0.92298851, 0.47834518, 0.89422527, 0.9196996 ,\n",
              "        0.72146659, 0.89623188, 0.91916859,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.94205393, 0.91609977, 0.82663731, 0.94387171,\n",
              "        0.91609977, 0.82663731, 0.94568325, 0.91609977, 0.82663731,\n",
              "        0.41134752, 0.87721302, 0.91671453, 0.4789644 , 0.88137536,\n",
              "        0.90887986, 0.72146659, 0.8975553 , 0.91266628,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.94022989, 0.91680815, 0.83150985,\n",
              "        0.94022989, 0.91680815, 0.83150985, 0.93968983, 0.91680815,\n",
              "        0.83150985, 0.41134752, 0.87179487, 0.91306851, 0.4789644 ,\n",
              "        0.87478361, 0.9063409 , 0.72061429, 0.89237929, 0.91322073,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.93894009, 0.91431793,\n",
              "        0.83115468, 0.93901036, 0.91431793, 0.83115468, 0.93908046,\n",
              "        0.91431793, 0.83115468, 0.41134752, 0.86777333, 0.911188  ,\n",
              "        0.4789644 , 0.87471264, 0.90719258, 0.72094395, 0.89341875,\n",
              "        0.91195335,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.93832853,\n",
              "        0.91483362, 0.83143631, 0.93724813, 0.91483362, 0.83143631,\n",
              "        0.93962047, 0.91483362, 0.83143631, 0.41134752, 0.871502  ,\n",
              "        0.90730012, 0.4789644 , 0.87377522, 0.90315053, 0.71952663,\n",
              "        0.89470622, 0.91458454]),\n",
              " 'mean_test_f1': array([       nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.90773786, 0.79119888,\n",
              "        0.44806693, 0.90972623, 0.79119888, 0.44806693, 0.90804077,\n",
              "        0.79119888, 0.44806693, 0.39167342, 0.86024876, 0.92882605,\n",
              "        0.44203979, 0.87584167, 0.92808544, 0.71648901, 0.89041174,\n",
              "        0.92513816,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.93839279,\n",
              "        0.88522413, 0.75767044, 0.9365196 , 0.88522413, 0.75767044,\n",
              "        0.93334958, 0.88522413, 0.75767044, 0.39167342, 0.87390917,\n",
              "        0.9323019 , 0.45672447, 0.89119534, 0.93057175, 0.71559421,\n",
              "        0.8995114 , 0.92925373,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.94067425, 0.91035026, 0.83510188, 0.94028485, 0.91035026,\n",
              "        0.83510188, 0.93944518, 0.91035026, 0.83510188, 0.39167342,\n",
              "        0.87554427, 0.9233109 , 0.46000017, 0.88829325, 0.92103329,\n",
              "        0.71517733, 0.89385376, 0.92004879,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.93788426, 0.914376  , 0.83764754, 0.9367721 ,\n",
              "        0.914376  , 0.83764754, 0.93753464, 0.914376  , 0.83764754,\n",
              "        0.39167342, 0.86832204, 0.91471514, 0.46016936, 0.87659247,\n",
              "        0.91210591, 0.71533384, 0.89241355, 0.91081443,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.93442367, 0.91542198, 0.83972747,\n",
              "        0.93315674, 0.91542198, 0.83972747, 0.93256504, 0.91542198,\n",
              "        0.83972747, 0.39167342, 0.8612275 , 0.91159704, 0.46016936,\n",
              "        0.8710388 , 0.90796548, 0.71602194, 0.89110826, 0.90859625,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.93187065, 0.91461391,\n",
              "        0.83830428, 0.93135646, 0.91461391, 0.83830428, 0.93159835,\n",
              "        0.91461391, 0.83830428, 0.39167342, 0.86055221, 0.90843264,\n",
              "        0.46016936, 0.87047479, 0.90791248, 0.71622512, 0.89238116,\n",
              "        0.90783008,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.93023961,\n",
              "        0.91438261, 0.83728453, 0.93069664, 0.91438261, 0.83728453,\n",
              "        0.93098942, 0.91438261, 0.83728453, 0.39167342, 0.85953202,\n",
              "        0.90627712, 0.46016936, 0.87024177, 0.90645601, 0.71545107,\n",
              "        0.89177904, 0.90928659]),\n",
              " 'std_test_f1': array([       nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.00571834, 0.01606389,\n",
              "        0.00991769, 0.00606224, 0.01606389, 0.00991769, 0.00586729,\n",
              "        0.01606389, 0.00991769, 0.01366901, 0.00805404, 0.00595929,\n",
              "        0.01814744, 0.00497624, 0.00689018, 0.00584247, 0.00553748,\n",
              "        0.00550592,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.005904  ,\n",
              "        0.00889239, 0.01700579, 0.00718823, 0.00889239, 0.01700579,\n",
              "        0.00650422, 0.00889239, 0.01700579, 0.01366901, 0.01088301,\n",
              "        0.00644883, 0.01771916, 0.00663546, 0.0067673 , 0.00774805,\n",
              "        0.00506323, 0.00589196,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.00624394, 0.00315729, 0.00566989, 0.00745169, 0.00315729,\n",
              "        0.00566989, 0.00751472, 0.00315729, 0.00566989, 0.01366901,\n",
              "        0.01537608, 0.00641302, 0.01848811, 0.00671394, 0.00501833,\n",
              "        0.00974305, 0.00759042, 0.00731942,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.0051191 , 0.00143728, 0.00755821, 0.00688493,\n",
              "        0.00143728, 0.00755821, 0.00676853, 0.00143728, 0.00755821,\n",
              "        0.01366901, 0.01334816, 0.00419017, 0.01865644, 0.00578083,\n",
              "        0.00837842, 0.00884869, 0.00589172, 0.00872098,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.00496658, 0.00197873, 0.00600562,\n",
              "        0.0072105 , 0.00197873, 0.00600562, 0.00704079, 0.00197873,\n",
              "        0.00600562, 0.01366901, 0.01082132, 0.0045997 , 0.01865644,\n",
              "        0.00666837, 0.00817347, 0.00920955, 0.00470688, 0.00715511,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.00606289, 0.00167985,\n",
              "        0.0053016 , 0.00586445, 0.00167985, 0.0053016 , 0.00647898,\n",
              "        0.00167985, 0.0053016 , 0.01366901, 0.00950991, 0.00549066,\n",
              "        0.01865644, 0.00467933, 0.00898715, 0.00736722, 0.00867621,\n",
              "        0.00595542,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.0067861 ,\n",
              "        0.00214569, 0.00583298, 0.00615948, 0.00214569, 0.00583298,\n",
              "        0.00673216, 0.00214569, 0.00583298, 0.01366901, 0.01065057,\n",
              "        0.00562109, 0.01865644, 0.00487108, 0.00837336, 0.00812614,\n",
              "        0.00694445, 0.00579567]),\n",
              " 'rank_test_f1': array([127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,\n",
              "        127, 127, 127, 127, 127,  55,  97, 116,  47,  97, 116,  51,  97,\n",
              "        116, 120,  80,  22, 119,  71,  23, 103,  65,  24, 127, 127, 127,\n",
              "        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,\n",
              "        127, 127,   4,  67, 100,   8,  67, 100,  10,  67, 100, 120,  73,\n",
              "         13, 115,  63,  19, 106,  58,  21, 127, 127, 127, 127, 127, 127,\n",
              "        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,   1,\n",
              "         44,  94,   2,  44,  94,   3,  44,  94, 120,  72,  25, 114,  66,\n",
              "         26, 109,  59,  27, 127, 127, 127, 127, 127, 127, 127, 127, 127,\n",
              "        127, 127, 127, 127, 127, 127, 127, 127, 127,   5,  38,  88,   7,\n",
              "         38,  88,   6,  38,  88, 120,  77,  31, 110,  70,  41, 108,  60,\n",
              "         43, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,\n",
              "        127, 127, 127, 127, 127, 127,   9,  28,  82,  11,  28,  82,  12,\n",
              "         28,  82, 120,  78,  42, 110,  74,  52, 105,  64,  49, 127, 127,\n",
              "        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,\n",
              "        127, 127, 127,  14,  32,  85,  16,  32,  85,  15,  32,  85, 120,\n",
              "         79,  50, 110,  75,  53, 104,  61,  54, 127, 127, 127, 127, 127,\n",
              "        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,\n",
              "         20,  35,  91,  18,  35,  91,  17,  35,  91, 120,  81,  57, 110,\n",
              "         76,  56, 107,  62,  48])}"
            ]
          },
          "execution_count": 432,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_cv.cv_results_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lrh7EKaHpng9",
        "outputId": "dbddd647-8a20-4b44-bd0e-4b7802d7ce7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best score: 0.941\n"
          ]
        }
      ],
      "source": [
        "print(\"Best score: %0.3f\" % grid_cv.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icJlmU_5png9"
      },
      "outputs": [],
      "source": [
        "cv_predictions = grid_cv.best_estimator_.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsWEApM9png9"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3e7LkYjfpng9"
      },
      "outputs": [],
      "source": [
        "def print_acc(predictions):\n",
        "    print(\"Precision: {0:6.2f}\".format(precision_score(y_test, predictions, average='macro')))\n",
        "    print(\"Recall:    {0:6.2f}\".format(recall_score(y_test, predictions, average='macro')))\n",
        "    print(\"F1_score:  {0:6.2f}\".format(f1_score(y_test, predictions, average='macro')))\n",
        "    print(\"Accuracy:  {0:6.2f}\".format(accuracy_score(y_test, predictions)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZZtQ5repng9",
        "outputId": "15819d31-70f6-4c32-d282-f0f9ed99f395"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision:   0.95\n",
            "Recall:      0.95\n",
            "F1_score:    0.95\n",
            "Accuracy:    0.95\n"
          ]
        }
      ],
      "source": [
        "print_acc(cv_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyleUD27png9",
        "outputId": "c125b77f-04b2-42cb-d80d-a397c64e86d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.94      0.96      0.95      1536\n",
            "         5.0       0.96      0.94      0.95      1464\n",
            "\n",
            "    accuracy                           0.95      3000\n",
            "   macro avg       0.95      0.95      0.95      3000\n",
            "weighted avg       0.95      0.95      0.95      3000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, cv_predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiY2aYVApng9",
        "outputId": "cdf72691-67bc-40bb-f426-3d3d3aeaddeb"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "labels = grid_cv.best_estimator_.classes_\n",
        "\n",
        "sns.heatmap(\n",
        "    data=confusion_matrix(y_test, cv_predictions),\n",
        "    annot=True,\n",
        "    fmt=\"d\",\n",
        "    cbar=False,\n",
        "    xticklabels=labels,\n",
        "    yticklabels=labels\n",
        ")\n",
        "\n",
        "plt.title(\"Confusion matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBcSKcd_png-"
      },
      "source": [
        "Сравните, как изменяется качество решения задачи при использовании скрытых тем в качестве признаков:\n",
        "\n",
        "1-ый вариант:\n",
        " преобразование (sklearn.feature_extraction.text.TfidfTransformer) и сингулярное разложение (оно же – латентый семантический анализ) (sklearn.decomposition.TruncatedSVD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3yyR7Pnpng-",
        "outputId": "28e370ad-7a83-4d88-f068-45dd4a44d3ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2093"
            ]
          },
          "execution_count": 447,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZuAhv8Tpng-"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXv-edhEpng-"
      },
      "outputs": [],
      "source": [
        "clf_tfidf = Pipeline(\n",
        "    [('vect', CountVectorizer()),\n",
        "     ('tfidf', TfidfTransformer()),\n",
        "     ('clf', LogisticRegression())]\n",
        ")\n",
        "\n",
        "params_tfidf = {\n",
        "    'vect__analyzer': ['word'],\n",
        "    'vect__max_df': (0.5, 0.75, 1.0),\n",
        "    'vect__ngram_range': [(1, 1), (2, 2), (3, 3)],\n",
        "    'tfidf__use_idf': (True, False),\n",
        "    'clf__C': np.logspace(-3, 3, 7),\n",
        "    'clf__penalty': ['l1', 'l2']\n",
        "}\n",
        "\n",
        "scores = ['accuracy','f1']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dwz3-gr8png-"
      },
      "outputs": [],
      "source": [
        "grid_tfidf = GridSearchCV(\n",
        "    clf_tfidf,\n",
        "    param_grid=params_tfidf,\n",
        "    cv=4,\n",
        "    scoring=scores,\n",
        "    refit=scores[0],\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYuDkPiBpng-",
        "outputId": "9980b489-1cb1-456c-bdab-b408204ba488"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 4 folds for each of 252 candidates, totalling 1008 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Suile\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
            "504 fits failed out of a total of 1008.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "504 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Suile\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Suile\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Suile\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 420, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"C:\\Users\\Suile\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Suile\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Suile\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Suile\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.59857143 0.50514286 0.50514286 0.598      0.50514286 0.50514286\n",
            " 0.596      0.50514286 0.50514286 0.74128571 0.50514286 0.50514286\n",
            " 0.73614286 0.50514286 0.50514286 0.72285714 0.50514286 0.50514286\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.87085714 0.58985714 0.50514286 0.87057143 0.58985714 0.50514286\n",
            " 0.87071429 0.58985714 0.50514286 0.85685714 0.72771429 0.509\n",
            " 0.85385714 0.72771429 0.509      0.83542857 0.72771429 0.509\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.90771429 0.87128571 0.70942857 0.90714286 0.87128571 0.70942857\n",
            " 0.90528571 0.87128571 0.70942857 0.895      0.84028571 0.74214286\n",
            " 0.895      0.84028571 0.74214286 0.887      0.84028571 0.74214286\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.93871429 0.90385714 0.84728571 0.93985714 0.90385714 0.84728571\n",
            " 0.93871429 0.90385714 0.84728571 0.92914286 0.88242857 0.83171429\n",
            " 0.92871429 0.88242857 0.83171429 0.92885714 0.88242857 0.83171429\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.94485714 0.91714286 0.85142857 0.94542857 0.91714286 0.85142857\n",
            " 0.94442857 0.91714286 0.85142857 0.94042857 0.90957143 0.837\n",
            " 0.94       0.90957143 0.837      0.93942857 0.90957143 0.837\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.94357143 0.92085714 0.85314286 0.94257143 0.92085714 0.85314286\n",
            " 0.94228571 0.92085714 0.85314286 0.93842857 0.91371429 0.83914286\n",
            " 0.93828571 0.91371429 0.83914286 0.93871429 0.91371429 0.83914286\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.94071429 0.92228571 0.854      0.94042857 0.92228571 0.854\n",
            " 0.93985714 0.92228571 0.854      0.93685714 0.91614286 0.83957143\n",
            " 0.93657143 0.91614286 0.83957143 0.93542857 0.91614286 0.83957143]\n",
            "  warnings.warn(\n",
            "C:\\Users\\Suile\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.32499729 0.         0.         0.32341412 0.         0.\n",
            " 0.31729848 0.         0.         0.665585   0.         0.\n",
            " 0.65678725 0.         0.         0.63641174 0.         0.\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.8657259  0.29986341 0.         0.86538248 0.29986341 0.\n",
            " 0.86586377 0.29986341 0.         0.85540292 0.64592149 0.0160236\n",
            " 0.85232633 0.64592149 0.0160236  0.83137837 0.64592149 0.0160236\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.90850332 0.86476718 0.60403712 0.90793475 0.86476718 0.60403712\n",
            " 0.90598127 0.86476718 0.60403712 0.89639474 0.83348748 0.6768639\n",
            " 0.89633431 0.83348748 0.6768639  0.88777442 0.83348748 0.6768639\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.93952686 0.90359547 0.84114401 0.94070237 0.90359547 0.84114401\n",
            " 0.93953821 0.90359547 0.84114401 0.93010147 0.88202062 0.82760055\n",
            " 0.92960309 0.88202062 0.82760055 0.92979153 0.88202062 0.82760055\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.94517364 0.91749825 0.84911979 0.94572717 0.91749825 0.84911979\n",
            " 0.94472089 0.91749825 0.84911979 0.94078944 0.90971943 0.83581873\n",
            " 0.94034423 0.90971943 0.83581873 0.9397485  0.90971943 0.83581873\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.94362537 0.92117694 0.85130768 0.94266245 0.92117694 0.85130768\n",
            " 0.9423541  0.92117694 0.85130768 0.9384987  0.91387176 0.83808629\n",
            " 0.93843312 0.91387176 0.83808629 0.93886633 0.91387176 0.83808629\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.94071018 0.92262116 0.85217245 0.94045226 0.92262116 0.85217245\n",
            " 0.93986431 0.92262116 0.85217245 0.93679316 0.9163889  0.83859242\n",
            " 0.93658712 0.9163889  0.83859242 0.93533698 0.9163889  0.83859242]\n",
            "  warnings.warn(\n",
            "C:\\Users\\Suile\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=4,\n",
              "             estimator=Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()),\n",
              "                                       (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
              "                                       (&#x27;clf&#x27;, LogisticRegression())]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;clf__C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
              "                         &#x27;clf__penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
              "                         &#x27;tfidf__use_idf&#x27;: (True, False),\n",
              "                         &#x27;vect__analyzer&#x27;: [&#x27;word&#x27;],\n",
              "                         &#x27;vect__max_df&#x27;: (0.5, 0.75, 1.0),\n",
              "                         &#x27;vect__ngram_range&#x27;: [(1, 1), (2, 2), (3, 3)]},\n",
              "             refit=&#x27;accuracy&#x27;, scoring=[&#x27;accuracy&#x27;, &#x27;f1&#x27;], verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=4,\n",
              "             estimator=Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()),\n",
              "                                       (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
              "                                       (&#x27;clf&#x27;, LogisticRegression())]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;clf__C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
              "                         &#x27;clf__penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
              "                         &#x27;tfidf__use_idf&#x27;: (True, False),\n",
              "                         &#x27;vect__analyzer&#x27;: [&#x27;word&#x27;],\n",
              "                         &#x27;vect__max_df&#x27;: (0.5, 0.75, 1.0),\n",
              "                         &#x27;vect__ngram_range&#x27;: [(1, 1), (2, 2), (3, 3)]},\n",
              "             refit=&#x27;accuracy&#x27;, scoring=[&#x27;accuracy&#x27;, &#x27;f1&#x27;], verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
              "                (&#x27;clf&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=4,\n",
              "             estimator=Pipeline(steps=[('vect', CountVectorizer()),\n",
              "                                       ('tfidf', TfidfTransformer()),\n",
              "                                       ('clf', LogisticRegression())]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'clf__C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
              "                         'clf__penalty': ['l1', 'l2'],\n",
              "                         'tfidf__use_idf': (True, False),\n",
              "                         'vect__analyzer': ['word'],\n",
              "                         'vect__max_df': (0.5, 0.75, 1.0),\n",
              "                         'vect__ngram_range': [(1, 1), (2, 2), (3, 3)]},\n",
              "             refit='accuracy', scoring=['accuracy', 'f1'], verbose=1)"
            ]
          },
          "execution_count": 451,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_tfidf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SyiKDIKopng_",
        "outputId": "9a8ebeb7-5ea6-43ab-88a0-c380cb0a9e3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best score: 0.945\n"
          ]
        }
      ],
      "source": [
        "print(\"Best score: %0.3f\" % grid_tfidf.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yokrBAF0png_"
      },
      "outputs": [],
      "source": [
        "tfidf_predictions = grid_tfidf.best_estimator_.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUIkq9WWpng_",
        "outputId": "747a4e83-d96b-4f31-e423-bdec02c13295"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision:   0.96\n",
            "Recall:      0.96\n",
            "F1_score:    0.96\n",
            "Accuracy:    0.96\n"
          ]
        }
      ],
      "source": [
        "print_acc(tfidf_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wF_QXapKpng_",
        "outputId": "72a05b15-2d43-4c91-ace7-1213dc1ad865"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.94      0.98      0.96      1536\n",
            "         5.0       0.97      0.94      0.96      1464\n",
            "\n",
            "    accuracy                           0.96      3000\n",
            "   macro avg       0.96      0.96      0.96      3000\n",
            "weighted avg       0.96      0.96      0.96      3000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, tfidf_predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1kq4ewApng_",
        "outputId": "0657f301-c0f9-4b71-93fd-c05df5e7de71"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "labels = grid_tfidf.best_estimator_.classes_\n",
        "\n",
        "sns.heatmap(\n",
        "    data=confusion_matrix(y_test, tfidf_predictions),\n",
        "    annot=True,\n",
        "    fmt=\"d\",\n",
        "    cbar=False,\n",
        "    xticklabels=labels,\n",
        "    yticklabels=labels\n",
        ")\n",
        "\n",
        "plt.title(\"Confusion matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jR6Hrl5png_"
      },
      "source": [
        "Cингулярное разложение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZFiWPkypng_"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import TruncatedSVD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eANeIHzDpng_"
      },
      "outputs": [],
      "source": [
        "clf_SVD = Pipeline(\n",
        "    [('vect', CountVectorizer()),\n",
        "     ('tfidf', TfidfTransformer()),\n",
        "     ('tsvd', TruncatedSVD()),\n",
        "     ('clf', LogisticRegression())]\n",
        ")\n",
        "\n",
        "params_SVD = {\n",
        "    'vect__analyzer': ['word'],\n",
        "    'vect__ngram_range': [(1, 1), (2, 2), (3, 3)],\n",
        "    'tsvd__n_components': [5, 10, 25, 50, 100],\n",
        "    'clf__C': np.logspace(-3, 3, 7),\n",
        "    'clf__penalty': ['l1', 'l2']\n",
        "}\n",
        "\n",
        "scores = ['accuracy','f1']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgiyKmyfpnhA"
      },
      "outputs": [],
      "source": [
        "grid_SVD = GridSearchCV(\n",
        "    clf_SVD,\n",
        "    param_grid=params_SVD,\n",
        "    cv=4,\n",
        "    scoring=scores,\n",
        "    refit=scores[0],\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQyHzS-ppnhA",
        "outputId": "5644c07f-ed8e-4129-a53a-f5fcad0bf122"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 4 folds for each of 210 candidates, totalling 840 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Suile\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
            "420 fits failed out of a total of 840.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "420 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Suile\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Suile\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Suile\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 420, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"C:\\Users\\Suile\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Suile\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Suile\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Suile\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.58271429 0.50514286 0.50514286\n",
            " 0.59842857 0.50514286 0.50514286 0.59414286 0.50514286 0.50514286\n",
            " 0.59528571 0.50514286 0.50514286 0.59628571 0.50514286 0.50514286\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.79642857 0.57271429 0.50514286\n",
            " 0.82685714 0.58071429 0.50514286 0.85685714 0.58671429 0.50514286\n",
            " 0.86385714 0.58928571 0.50514286 0.86685714 0.58814286 0.50514286\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.80957143 0.77785714 0.51585714\n",
            " 0.85014286 0.79485714 0.52842857 0.88371429 0.82242857 0.54385714\n",
            " 0.89542857 0.84       0.56142857 0.89885714 0.84614286 0.58442857\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.81285714 0.798      0.60928571\n",
            " 0.85971429 0.821      0.63714286 0.905      0.85514286 0.69971429\n",
            " 0.925      0.86657143 0.73057143 0.93057143 0.876      0.76042857\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.81357143 0.80485714 0.641\n",
            " 0.86       0.82457143 0.68671429 0.91557143 0.86685714 0.72657143\n",
            " 0.93085714 0.88471429 0.76514286 0.93828571 0.898      0.77557143\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.813      0.80914286 0.67414286\n",
            " 0.86071429 0.82842857 0.66728571 0.91371429 0.866      0.74242857\n",
            " 0.93214286 0.888      0.75657143 0.93885714 0.89642857 0.77014286\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.81314286 0.80628571 0.67028571\n",
            " 0.86085714 0.83328571 0.705      0.91714286 0.87214286 0.72628571\n",
            " 0.93214286 0.88371429 0.75671429 0.93642857 0.89585714 0.77542857]\n",
            "  warnings.warn(\n",
            "C:\\Users\\Suile\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.29040175 0.         0.\n",
            " 0.32646456 0.         0.         0.31365223 0.         0.\n",
            " 0.31560337 0.         0.         0.31814188 0.         0.\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.78091033 0.25566505 0.\n",
            " 0.81590045 0.27882204 0.         0.85110766 0.29413451 0.\n",
            " 0.85863204 0.30027996 0.         0.8619275  0.29660701 0.\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.80447399 0.75266394 0.04631156\n",
            " 0.84741965 0.77318624 0.1050311  0.88439275 0.80869272 0.16353878\n",
            " 0.89624386 0.82857716 0.22804281 0.89949475 0.83637659 0.30286368\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.80940509 0.78837552 0.42108929\n",
            " 0.85826994 0.81468998 0.50945695 0.90589572 0.85195466 0.6410033\n",
            " 0.9259358  0.86435115 0.68922856 0.93128683 0.87465607 0.73461891\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.81053706 0.79804429 0.58735776\n",
            " 0.85868808 0.8192318  0.64685679 0.91604058 0.86524559 0.71489119\n",
            " 0.93120297 0.88399503 0.76179238 0.93847885 0.89762664 0.77294704\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.81007411 0.80259386 0.6655861\n",
            " 0.85944472 0.82389853 0.63628075 0.91373782 0.86275964 0.73325988\n",
            " 0.9320203  0.88590659 0.75097537 0.93880976 0.89500992 0.76693248\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.81007754 0.79966816 0.65776941\n",
            " 0.85965883 0.82845798 0.69700644 0.91730599 0.86946114 0.72677263\n",
            " 0.93190418 0.88142078 0.75276738 0.93644393 0.89386168 0.76939391]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=4,\n",
              "             estimator=Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()),\n",
              "                                       (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
              "                                       (&#x27;tsvd&#x27;, TruncatedSVD()),\n",
              "                                       (&#x27;clf&#x27;, LogisticRegression())]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;clf__C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
              "                         &#x27;clf__penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
              "                         &#x27;tsvd__n_components&#x27;: [5, 10, 25, 50, 100],\n",
              "                         &#x27;vect__analyzer&#x27;: [&#x27;word&#x27;],\n",
              "                         &#x27;vect__ngram_range&#x27;: [(1, 1), (2, 2), (3, 3)]},\n",
              "             refit=&#x27;accuracy&#x27;, scoring=[&#x27;accuracy&#x27;, &#x27;f1&#x27;], verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=4,\n",
              "             estimator=Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()),\n",
              "                                       (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
              "                                       (&#x27;tsvd&#x27;, TruncatedSVD()),\n",
              "                                       (&#x27;clf&#x27;, LogisticRegression())]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;clf__C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
              "                         &#x27;clf__penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
              "                         &#x27;tsvd__n_components&#x27;: [5, 10, 25, 50, 100],\n",
              "                         &#x27;vect__analyzer&#x27;: [&#x27;word&#x27;],\n",
              "                         &#x27;vect__ngram_range&#x27;: [(1, 1), (2, 2), (3, 3)]},\n",
              "             refit=&#x27;accuracy&#x27;, scoring=[&#x27;accuracy&#x27;, &#x27;f1&#x27;], verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
              "                (&#x27;tsvd&#x27;, TruncatedSVD()), (&#x27;clf&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TruncatedSVD</label><div class=\"sk-toggleable__content\"><pre>TruncatedSVD()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=4,\n",
              "             estimator=Pipeline(steps=[('vect', CountVectorizer()),\n",
              "                                       ('tfidf', TfidfTransformer()),\n",
              "                                       ('tsvd', TruncatedSVD()),\n",
              "                                       ('clf', LogisticRegression())]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'clf__C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
              "                         'clf__penalty': ['l1', 'l2'],\n",
              "                         'tsvd__n_components': [5, 10, 25, 50, 100],\n",
              "                         'vect__analyzer': ['word'],\n",
              "                         'vect__ngram_range': [(1, 1), (2, 2), (3, 3)]},\n",
              "             refit='accuracy', scoring=['accuracy', 'f1'], verbose=1)"
            ]
          },
          "execution_count": 462,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_SVD.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t200RztTpnhA",
        "outputId": "dba9f204-2e90-4e0a-9178-9ede4f44ecb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best score: 0.939\n"
          ]
        }
      ],
      "source": [
        "print(\"Best score: %0.3f\" % grid_SVD.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xNdfij1pnhA"
      },
      "outputs": [],
      "source": [
        "svd_predictions = grid_SVD.best_estimator_.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsfc_ZrrpnhA",
        "outputId": "50516c7a-5a68-497e-a23c-4e5544eb1ad7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision:   0.95\n",
            "Recall:      0.95\n",
            "F1_score:    0.95\n",
            "Accuracy:    0.95\n"
          ]
        }
      ],
      "source": [
        "print_acc(svd_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1iLsBBhpnhA",
        "outputId": "2ddaf12e-61cf-48fd-912e-377a58eea80f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.94      0.96      0.95      1536\n",
            "         5.0       0.95      0.94      0.95      1464\n",
            "\n",
            "    accuracy                           0.95      3000\n",
            "   macro avg       0.95      0.95      0.95      3000\n",
            "weighted avg       0.95      0.95      0.95      3000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, svd_predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftACQBdZpnhB",
        "outputId": "5333b2d6-8482-41a9-99c2-ef2c1dbfaa2d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "labels = grid_SVD.best_estimator_.classes_\n",
        "\n",
        "sns.heatmap(\n",
        "    data=confusion_matrix(y_test, svd_predictions),\n",
        "    annot=True,\n",
        "    fmt=\"d\",\n",
        "    cbar=False,\n",
        "    xticklabels=labels,\n",
        "    yticklabels=labels\n",
        ")\n",
        "\n",
        "plt.title(\"Confusion matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFOnm2MKpnhB"
      },
      "source": [
        "2-ой вариант: тематические модели LDA (sklearn.decomposition.LatentDirichletAllocation). Используйте accuracy и F-measure для оценки качества классификации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Qf_Bkt2pnhB",
        "outputId": "4f700f25-8a0a-4901-d2ea-61f511651900"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6670"
            ]
          },
          "execution_count": 474,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4Jq0FOtpnhB"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ENaAxY1pnhB"
      },
      "outputs": [],
      "source": [
        "clf_LDA = Pipeline(\n",
        "    [('vect', CountVectorizer()),\n",
        "     ('lda', LatentDirichletAllocation()),\n",
        "     ('clf', LogisticRegression())]\n",
        ")\n",
        "\n",
        "params_LDA = {\n",
        "    'vect__analyzer': ['word'],\n",
        "    'vect__max_df': [0.75],\n",
        "    'vect__ngram_range': [(1, 1)],\n",
        "    'lda__n_components' : [25, 50, 100],\n",
        "    'clf__C': np.logspace(-3, 3, 7),\n",
        "    'clf__penalty': ['l2']\n",
        "}\n",
        "\n",
        "scores = ['accuracy', 'f1']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBEKvaQHpnhB"
      },
      "outputs": [],
      "source": [
        "grid_LDA = GridSearchCV(\n",
        "    clf_LDA,\n",
        "    param_grid=params_LDA,\n",
        "    cv=4,\n",
        "    scoring=scores,\n",
        "    refit=scores[0],\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uK_WWAZnpnhB",
        "outputId": "950ae253-c51a-4c9d-eb17-7fcbbc5a6cfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=4,\n",
              "             estimator=Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()),\n",
              "                                       (&#x27;lda&#x27;, LatentDirichletAllocation()),\n",
              "                                       (&#x27;clf&#x27;, LogisticRegression())]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;clf__C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
              "                         &#x27;clf__penalty&#x27;: [&#x27;l2&#x27;],\n",
              "                         &#x27;lda__n_components&#x27;: [25, 50, 100],\n",
              "                         &#x27;vect__analyzer&#x27;: [&#x27;word&#x27;], &#x27;vect__max_df&#x27;: [0.75],\n",
              "                         &#x27;vect__ngram_range&#x27;: [(1, 1)]},\n",
              "             refit=&#x27;accuracy&#x27;, scoring=[&#x27;accuracy&#x27;, &#x27;f1&#x27;], verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=4,\n",
              "             estimator=Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()),\n",
              "                                       (&#x27;lda&#x27;, LatentDirichletAllocation()),\n",
              "                                       (&#x27;clf&#x27;, LogisticRegression())]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;clf__C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
              "                         &#x27;clf__penalty&#x27;: [&#x27;l2&#x27;],\n",
              "                         &#x27;lda__n_components&#x27;: [25, 50, 100],\n",
              "                         &#x27;vect__analyzer&#x27;: [&#x27;word&#x27;], &#x27;vect__max_df&#x27;: [0.75],\n",
              "                         &#x27;vect__ngram_range&#x27;: [(1, 1)]},\n",
              "             refit=&#x27;accuracy&#x27;, scoring=[&#x27;accuracy&#x27;, &#x27;f1&#x27;], verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()),\n",
              "                (&#x27;lda&#x27;, LatentDirichletAllocation()),\n",
              "                (&#x27;clf&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=4,\n",
              "             estimator=Pipeline(steps=[('vect', CountVectorizer()),\n",
              "                                       ('lda', LatentDirichletAllocation()),\n",
              "                                       ('clf', LogisticRegression())]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'clf__C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
              "                         'clf__penalty': ['l2'],\n",
              "                         'lda__n_components': [25, 50, 100],\n",
              "                         'vect__analyzer': ['word'], 'vect__max_df': [0.75],\n",
              "                         'vect__ngram_range': [(1, 1)]},\n",
              "             refit='accuracy', scoring=['accuracy', 'f1'], verbose=1)"
            ]
          },
          "execution_count": 482,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_LDA.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "teYipxWMpnhB",
        "outputId": "c92b6700-f20f-4fed-f240-3ab776f120fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best score: 0.905\n"
          ]
        }
      ],
      "source": [
        "print(\"Best score: %0.3f\" % grid_LDA.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrRFXf-ZpnhC"
      },
      "outputs": [],
      "source": [
        "lda_predictions = grid_LDA.best_estimator_.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCrGkwrXpnhC",
        "outputId": "2b7ed9c7-03f7-49aa-df3c-2851ab56aff7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision:   0.91\n",
            "Recall:      0.91\n",
            "F1_score:    0.91\n",
            "Accuracy:    0.91\n"
          ]
        }
      ],
      "source": [
        "print_acc(lda_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvZaimhopnhC",
        "outputId": "66051183-5ea5-473b-db36-af6e83b19f75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.89      0.93      0.91      1536\n",
            "         5.0       0.92      0.89      0.90      1464\n",
            "\n",
            "    accuracy                           0.91      3000\n",
            "   macro avg       0.91      0.91      0.91      3000\n",
            "weighted avg       0.91      0.91      0.91      3000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, lda_predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tf0UmVI6pnhC",
        "outputId": "c894ad32-df25-43ad-c035-a39da97ec84f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "labels = grid_LDA.best_estimator_.classes_\n",
        "\n",
        "sns.heatmap(\n",
        "    data=confusion_matrix(y_test, lda_predictions),\n",
        "    annot=True,\n",
        "    fmt=\"d\",\n",
        "    cbar=False,\n",
        "    xticklabels=labels,\n",
        "    yticklabels=labels\n",
        ")\n",
        "\n",
        "plt.title(\"Confusion matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2jhadcQpnhC",
        "outputId": "83a421ef-07cd-4f3a-adfb-bb6e2a4abf4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cv\n",
            "f1_score:  0.953\n",
            "Accuracy:  0.953\n",
            "\n",
            "\n",
            "tfidf\n",
            "f1_score:  0.958\n",
            "Accuracy:  0.958\n",
            "\n",
            "\n",
            "SVD\n",
            "f1_score:  0.948\n",
            "Accuracy:  0.948\n",
            "\n",
            "\n",
            "LDA\n",
            "f1_score:  0.906\n",
            "Accuracy:  0.906\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for model in ['grid_cv', 'grid_tfidf', 'grid_SVD', 'grid_LDA']:\n",
        "    print(model[5:])\n",
        "    predictions = eval(model).best_estimator_.predict(X_test)\n",
        "    print(\"f1_score: {0:6.3f}\\nAccuracy: {0:6.3f}\\n\\n\".format(\n",
        "        f1_score(y_test, predictions, average='macro'),\n",
        "        accuracy_score(y_test, predictions)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whXlWQPupnhD"
      },
      "source": [
        "#### Выводы:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Uy8ECMopnhD"
      },
      "source": [
        "Модель на основк 𝑡𝑓−𝑖𝑑𝑓 имеет больший процент правильных ответов на тестовой выборке"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}